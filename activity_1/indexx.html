<!doctype html>
<html lang="en">
    <head>
        <title data-rh="true">The Math Behind Neural Networks | Towards Data Science</title>
        <style type="text/css" data-fela-rehydration="606" data-fela-type="STATIC">
            html {
                box-sizing: border-box;
                -webkit-text-size-adjust: 100%
            }

            *, *:before, *:after {
                box-sizing: inherit
            }

            body {
                margin: 0;
                padding: 0;
                text-rendering: optimizeLegibility;
                -webkit-font-smoothing: antialiased;
                color: rgba(0,0,0,0.8);
                position: relative;
                min-height: 100vh
            }

            h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form {
                margin: 0
            }

            menu, ol, ul {
                padding: 0;
                list-style: none;
                list-style-image: none
            }

            main {
                display: block
            }

            a {
                color: inherit;
                text-decoration: none
            }

            a, button, input {
                -webkit-tap-highlight-color: transparent
            }

            img, svg {
                vertical-align: middle
            }

            button {
                background: transparent;
                overflow: visible
            }

            button, input, optgroup, select, textarea {
                margin: 0
            }

            :root {
                --reach-tabs: 1;
                --reach-menu-button: 1
            }

            #speechify-root {
                font-family: Sohne, sans-serif
            }

            div[data-popper-reference-hidden="true"] {
                visibility: hidden;
                pointer-events: none
            }

            /*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/
            .hljs {
                background: #fff;
                color: black;
            }

            /* Gray DOCTYPE selectors like WebKit */
            .xml .hljs-meta {
                color: #c0c0c0;
            }

            .hljs-comment, .hljs-quote {
                color: #007400;
            }

            .hljs-tag, .hljs-attribute, .hljs-keyword, .hljs-selector-tag, .hljs-literal, .hljs-name {
                color: #aa0d91;
            }

            .hljs-variable, .hljs-template-variable {
                color: #3F6E74;
            }

            .hljs-code, .hljs-string, .hljs-meta .hljs-string {
                color: #c41a16;
            }

            .hljs-regexp, .hljs-link {
                color: #0E0EFF;
            }

            .hljs-title, .hljs-symbol, .hljs-bullet, .hljs-number {
                color: #1c00cf;
            }

            .hljs-section, .hljs-meta {
                color: #643820;
            }

            .hljs-title.class_, .hljs-class .hljs-title, .hljs-type, .hljs-built_in, .hljs-params {
                color: #5c2699;
            }

            .hljs-attr {
                color: #836C28;
            }

            .hljs-subst {
                color: #000;
            }

            .hljs-formula {
                background-color: #eee;
                font-style: italic;
            }

            .hljs-addition {
                background-color: #baeeba;
            }

            .hljs-deletion {
                background-color: #ffc8bd;
            }

            .hljs-selector-id, .hljs-selector-class {
                color: #9b703f;
            }

            .hljs-doctag, .hljs-strong {
                font-weight: bold;
            }

            .hljs-emphasis {
                font-style: italic;
            }
        </style>
        <style type="text/css" data-fela-rehydration="606" data-fela-type="RULE">
            .a {
                font-family: medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif
            }

            .b {
                font-weight: 400
            }

            .c {
                background-color: rgba(255, 255, 255, 1)
            }

            .l {
                display: block
            }

            .m {
                position: sticky
            }

            .n {
                top: 0
            }

            .o {
                z-index: 500
            }

            .p {
                padding: 0 24px
            }

            .q {
                align-items: center
            }

            .r {
                border-bottom: solid 1px #F2F2F2
            }

            .y {
                height: 41px
            }

            .z {
                line-height: 20px
            }

            .ab {
                display: flex
            }

            .ac {
                height: 57px
            }

            .ae {
                flex: 1 0 auto
            }

            .af {
                color: inherit
            }

            .ag {
                fill: inherit
            }

            .ah {
                font-size: inherit
            }

            .ai {
                border: inherit
            }

            .aj {
                font-family: inherit
            }

            .ak {
                letter-spacing: inherit
            }

            .al {
                font-weight: inherit
            }

            .am {
                padding: 0
            }

            .an {
                margin: 0
            }

            .ao {
                cursor: pointer
            }

            .ap:disabled {
                cursor: not-allowed
            }

            .aq:disabled {
                color: #6B6B6B
            }

            .ar:disabled {
                fill: #6B6B6B
            }

            .au {
                fill: rgba(0, 0, 0, 1)
            }

            .av {
                height: 22px
            }

            .aw {
                margin-left: 16px
            }

            .ax {
                border: none
            }

            .ay {
                border-radius: 20px
            }

            .az {
                width: 240px
            }

            .ba {
                background: #F9F9F9
            }

            .bb path {
                fill: #6B6B6B
            }

            .bd {
                outline: none
            }

            .be {
                font-family: sohne, "Helvetica Neue", Helvetica, Arial, sans-serif
            }

            .bf {
                font-size: 14px
            }

            .bg {
                width: 100%
            }

            .bh {
                padding: 10px 20px 10px 0
            }

            .bi {
                background-color: transparent
            }

            .bj {
                color: #242424
            }

            .bk::placeholder {
                color: #6B6B6B
            }

            .bl {
                display: inline-block
            }

            .bm {
                margin-left: 12px
            }

            .bn {
                margin-right: 12px
            }

            .bo {
                border-radius: 4px
            }

            .bp {
                margin-left: 24px
            }

            .bq {
                height: 24px
            }

            .bw {
                background-color: #F9F9F9
            }

            .bx {
                border-radius: 50%
            }

            .by {
                height: 32px
            }

            .bz {
                width: 32px
            }

            .ca {
                justify-content: center
            }

            .cg {
                max-width: 680px
            }

            .ch {
                min-width: 0
            }

            .ci {
                animation: k1 1.2s ease-in-out infinite
            }

            .cj {
                height: 100vh
            }

            .ck {
                margin-bottom: 16px
            }

            .cl {
                margin-top: 48px
            }

            .cm {
                align-items: flex-start
            }

            .cn {
                flex-direction: column
            }

            .co {
                justify-content: space-between
            }

            .cp {
                margin-bottom: 24px
            }

            .cv {
                width: 80%
            }

            .cw {
                background-color: #F2F2F2
            }

            .dc {
                height: 44px
            }

            .dd {
                width: 44px
            }

            .de {
                margin: auto 0
            }

            .df {
                margin-bottom: 4px
            }

            .dg {
                height: 16px
            }

            .dh {
                width: 120px
            }

            .di {
                width: 80px
            }

            .do {
                margin-bottom: 8px
            }

            .dp {
                width: 96%
            }

            .dq {
                width: 98%
            }

            .dr {
                width: 81%
            }

            .ds {
                margin-left: 8px
            }

            .dt {
                color: #6B6B6B
            }

            .du {
                font-size: 13px
            }

            .dv {
                height: 100%
            }

            .eo {
                color: #FFFFFF
            }

            .ep {
                fill: #FFFFFF
            }

            .eq {
                background: rgba(102, 138, 170, 1)
            }

            .er {
                border-color: rgba(102, 138, 170, 1)
            }

            .ev:disabled {
                cursor: inherit !important
            }

            .ew:disabled {
                opacity: 0.3
            }

            .ex:disabled:hover {
                background: rgba(102, 138, 170, 1)
            }

            .ey:disabled:hover {
                border-color: rgba(102, 138, 170, 1)
            }

            .ez {
                border-radius: 99em
            }

            .fa {
                border-width: 1px
            }

            .fb {
                border-style: solid
            }

            .fc {
                box-sizing: border-box
            }

            .fd {
                text-decoration: none
            }

            .fe {
                text-align: center
            }

            .fh {
                margin-right: 32px
            }

            .fi {
                position: relative
            }

            .fj {
                fill: #6B6B6B
            }

            .fm {
                background: transparent
            }

            .fn svg {
                margin-left: 4px
            }

            .fo svg {
                fill: #6B6B6B
            }

            .fq {
                box-shadow: inset 0 0 0 1px rgba(0, 0, 0, 0.05)
            }

            .fr {
                position: absolute
            }

            .ft {
                display: none
            }

            .fz {
                margin: 0 24px
            }

            .gd {
                background: rgba(255, 255, 255, 1)
            }

            .ge {
                border: 1px solid #F2F2F2
            }

            .gf {
                box-shadow: 0 1px 4px #F2F2F2
            }

            .gg {
                max-height: 100vh
            }

            .gh {
                overflow-y: auto
            }

            .gi {
                left: 0
            }

            .gj {
                top: calc(100vh + 100px)
            }

            .gk {
                bottom: calc(100vh + 100px)
            }

            .gl {
                width: 10px
            }

            .gm {
                pointer-events: none
            }

            .gn {
                word-break: break-word
            }

            .go {
                word-wrap: break-word
            }

            .gp:after {
                display: block
            }

            .gq:after {
                content: ""
            }

            .gr:after {
                clear: both
            }

            .gs {
                line-height: 1.23
            }

            .gt {
                letter-spacing: 0
            }

            .gu {
                font-style: normal
            }

            .gv {
                font-weight: 700
            }

            .hq {
                margin-bottom: -0.27em
            }

            .hr {
                line-height: 1.394
            }

            .ih {
                @media all and (max-width: 551.98px):8px
            }

            .ii {
                @media all and (min-width: 552px) and (max-width: 727.98px):8px
            }

            .ij {
                @media all and (min-width: 728px) and (max-width: 903.98px):16px
            }

            .ik {
                @media all and (min-width: 904px) and (max-width: 1079.98px):16px
            }

            .il {
                @media all and (min-width: 1080px):16px
            }

            .ir {
                align-items: baseline
            }

            .is {
                width: 48px
            }

            .it {
                height: 48px
            }

            .iu {
                border: 2px solid rgba(255, 255, 255, 1)
            }

            .iv {
                z-index: 0
            }

            .iw {
                box-shadow: none
            }

            .ix {
                border: 1px solid rgba(0, 0, 0, 0.05)
            }

            .iy {
                margin-left: -12px
            }

            .iz {
                width: 28px
            }

            .ja {
                height: 28px
            }

            .jb {
                z-index: 1
            }

            .jc {
                width: 24px
            }

            .jd {
                margin-bottom: 2px
            }

            .je {
                flex-wrap: nowrap
            }

            .jf {
                font-size: 16px
            }

            .jg {
                line-height: 24px
            }

            .ji {
                margin: 0 8px
            }

            .jj {
                display: inline
            }

            .jk {
                color: rgba(102, 138, 170, 1)
            }

            .jl {
                fill: rgba(102, 138, 170, 1)
            }

            .jo {
                flex: 0 0 auto
            }

            .jr {
                flex-wrap: wrap
            }

            .ju {
                white-space: pre-wrap
            }

            .jv {
                margin-right: 4px
            }

            .jw {
                overflow: hidden
            }

            .jx {
                max-height: 20px
            }

            .jy {
                text-overflow: ellipsis
            }

            .jz {
                display: -webkit-box
            }

            .ka {
                -webkit-line-clamp: 1
            }

            .kb {
                -webkit-box-orient: vertical
            }

            .kc {
                word-break: break-all
            }

            .ke {
                padding-left: 8px
            }

            .kf {
                padding-right: 8px
            }

            .lg> * {
                flex-shrink: 0
            }

            .lh {
                overflow-x: scroll
            }

            .li::-webkit-scrollbar {
                display: none
            }

            .lj {
                scrollbar-width: none
            }

            .lk {
                -ms-overflow-style: none
            }

            .ll {
                width: 74px
            }

            .lm {
                flex-direction: row
            }

            .ln {
                z-index: 2
            }

            .lq {
                -webkit-user-select: none
            }

            .lr {
                border: 0
            }

            .ls {
                fill: rgba(117, 117, 117, 1)
            }

            .lv {
                outline: 0
            }

            .lw {
                user-select: none
            }

            .lx> svg {
                pointer-events: none
            }

            .mg {
                cursor: progress
            }

            .mh {
                margin-left: 4px
            }

            .mi {
                margin-top: 0px
            }

            .mj {
                opacity: 1
            }

            .mk {
                padding: 4px 0
            }

            .mn {
                width: 16px
            }

            .mp {
                display: inline-flex
            }

            .mv {
                max-width: 100%
            }

            .mw {
                padding: 8px 2px
            }

            .mx svg {
                color: #6B6B6B
            }

            .no {
                margin-left: auto
            }

            .np {
                margin-right: auto
            }

            .nq {
                max-width: 1792px
            }

            .nw {
                clear: both
            }

            .ny {
                cursor: zoom-in
            }

            .nz {
                z-index: auto
            }

            .ob {
                height: auto
            }

            .oc {
                margin-top: 10px
            }

            .od {
                max-width: 728px
            }

            .og {
                line-height: 1.58
            }

            .oh {
                letter-spacing: -0.004em
            }

            .oi {
                font-family: source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif
            }

            .pb {
                margin-bottom: -0.46em
            }

            .pc {
                margin-top: 32px
            }

            .pd {
                margin-bottom: 14px
            }

            .pe {
                padding-top: 24px
            }

            .pf {
                padding-bottom: 10px
            }

            .pg {
                background-color: #000000
            }

            .ph {
                height: 3px
            }

            .pi {
                width: 3px
            }

            .pj {
                margin-right: 20px
            }

            .pk {
                text-decoration: underline
            }

            .pl {
                line-height: 1.12
            }

            .pm {
                letter-spacing: -0.022em
            }

            .pn {
                font-weight: 600
            }

            .qg {
                margin-bottom: -0.28em
            }

            .qh {
                line-height: 1.18
            }

            .qv {
                margin-bottom: -0.31em
            }

            .rg {
                max-width: 660px
            }

            .rh {
                max-width: 331px
            }

            .ri {
                list-style-type: disc
            }

            .rj {
                margin-left: 30px
            }

            .rk {
                padding-left: 0px
            }

            .rl {
                font-style: italic
            }

            .rr {
                max-width: 420px
            }

            .rs {
                max-width: 238px
            }

            .rt {
                max-width: 431px
            }

            .ru {
                max-width: 520px
            }

            .rv {
                max-width: 415px
            }

            .rw {
                max-width: 302px
            }

            .rx {
                max-width: 332px
            }

            .ry {
                max-width: 549px
            }

            .rz {
                max-width: 259px
            }

            .sa {
                max-width: 314px
            }

            .sb {
                max-width: 372px
            }

            .sc {
                max-width: 441px
            }

            .sd {
                max-width: 509px
            }

            .se {
                max-width: 437px
            }

            .sf {
                max-width: 345px
            }

            .sg {
                max-width: 642px
            }

            .sh {
                max-width: 205px
            }

            .si {
                max-width: 263px
            }

            .sj {
                max-width: 268px
            }

            .sk {
                max-width: 361px
            }

            .sq {
                box-shadow: inset 0 0 0 1px #F2F2F2
            }

            .sr {
                padding: 0px
            }

            .ss {
                padding: 16px 20px
            }

            .st {
                flex: 1 1 auto
            }

            .sv {
                max-height: 40px
            }

            .sw {
                -webkit-line-clamp: 2
            }

            .sx {
                margin-top: 8px
            }

            .sy {
                margin-top: 12px
            }

            .sz {
                width: 160px
            }

            .ta {
                background-image: url(https://miro.medium.com/v2/da:true/resize:fit:320/0*CkJMZeaiWvZuyhU4)
            }

            .tb {
                background-origin: border-box
            }

            .tc {
                background-size: cover
            }

            .td {
                height: 167px
            }

            .te {
                background-position: 50% 50%
            }

            .tf {
                background-image: url(https://miro.medium.com/v2/resize:fit:320/1*IHcsI8oOdaU6myihjShlrA.png)
            }

            .tg {
                background-image: url(https://miro.medium.com/v2/da:true/resize:fit:320/0*WLId-WgYwuz9YBHc)
            }

            .th {
                overflow-x: auto
            }

            .ti {
                font-family: source-code-pro, Menlo, Monaco, "Courier New", Courier, monospace
            }

            .tj {
                padding: 32px
            }

            .tk {
                border: 1px solid #E5E5E5
            }

            .tl {
                line-height: 1.4
            }

            .tm {
                margin-top: -0.2em
            }

            .tn {
                margin-bottom: -0.2em
            }

            .to {
                white-space: pre
            }

            .tp {
                min-width: fit-content
            }

            .tq {
                padding: 2px 4px
            }

            .tr {
                font-size: 75%
            }

            .ts> strong {
                font-family: inherit
            }

            .tt {
                list-style-type: decimal
            }

            .tu {
                max-width: 990px
            }

            .tv {
                margin-bottom: 26px
            }

            .tw {
                margin-top: 6px
            }

            .tx {
                margin-right: 8px
            }

            .ty {
                padding: 8px 16px
            }

            .tz {
                border-radius: 100px
            }

            .ua {
                transition: background 300ms ease
            }

            .uc {
                white-space: nowrap
            }

            .ud {
                border-top: none
            }

            .uj {
                height: 52px
            }

            .uk {
                max-height: 52px
            }

            .ul {
                box-sizing: content-box
            }

            .um {
                position: static
            }

            .uo {
                max-width: 155px
            }

            .uz {
                align-items: flex-end
            }

            .va {
                width: 76px
            }

            .vb {
                height: 76px
            }

            .vc {
                border: 2px solid #F9F9F9
            }

            .vd {
                height: 72px
            }

            .ve {
                width: 72px
            }

            .vf {
                margin-left: -16px
            }

            .vg {
                width: 36px
            }

            .vh {
                height: 36px
            }

            .vi {
                width: auto
            }

            .vj {
                stroke: #F2F2F2
            }

            .vk {
                color: #F2F2F2
            }

            .vl {
                fill: #F2F2F2
            }

            .vm {
                background: #F2F2F2
            }

            .vn {
                border-color: #F2F2F2
            }

            .vt {
                font-weight: 500
            }

            .vu {
                font-size: 24px
            }

            .vv {
                line-height: 30px
            }

            .vw {
                letter-spacing: -0.016em
            }

            .vx {
                margin-top: 16px
            }

            .vy {
                height: 0px
            }

            .vz {
                border-bottom: solid 1px #E5E5E5
            }

            .wf {
                margin-top: 72px
            }

            .wg {
                padding: 24px 0
            }

            .wh {
                margin-bottom: 0px
            }

            .wi {
                margin-right: 16px
            }

            .as:hover:not(:disabled) {
                color: rgba(25, 25, 25, 1)
            }

            .at:hover:not(:disabled) {
                fill: rgba(25, 25, 25, 1)
            }

            .es:hover {
                background: rgba(90, 118, 144, 1)
            }

            .et:hover {
                border-color: rgba(90, 118, 144, 1)
            }

            .eu:hover {
                cursor: pointer
            }

            .fk:hover {
                color: #242424
            }

            .fl:hover {
                fill: #242424
            }

            .fp:hover svg {
                fill: #242424
            }

            .fs:hover {
                background-color: rgba(0, 0, 0, 0.1)
            }

            .jh:hover {
                text-decoration: underline
            }

            .jm:hover:not(:disabled) {
                color: rgba(90, 118, 144, 1)
            }

            .jn:hover:not(:disabled) {
                fill: rgba(90, 118, 144, 1)
            }

            .lu:hover {
                fill: rgba(8, 8, 8, 1)
            }

            .ml:hover {
                fill: #000000
            }

            .mm:hover p {
                color: #000000
            }

            .mo:hover {
                color: #000000
            }

            .my:hover svg {
                color: #000000
            }

            .ub:hover {
                background-color: #F2F2F2
            }

            .vo:hover {
                background: #F2F2F2
            }

            .vp:hover {
                border-color: #F2F2F2
            }

            .vq:hover {
                cursor: wait
            }

            .vr:hover {
                color: #F2F2F2
            }

            .vs:hover {
                fill: #F2F2F2
            }

            .bc:focus-within path {
                fill: #242424
            }

            .lt:focus {
                fill: rgba(8, 8, 8, 1)
            }

            .mz:focus svg {
                color: #000000
            }

            .oa:focus {
                transform: scale(1.01)
            }

            .ly:active {
                border-style: none
            }
        </style>
        <style type="text/css" data-fela-rehydration="606" data-fela-type="RULE" media="all and (min-width: 1080px)">
            .d {
                display: none
            }

            .bv {
                width: 64px
            }

            .cf {
                margin: 0 64px
            }

            .cu {
                height: 48px
            }

            .db {
                margin-bottom: 52px
            }

            .dn {
                margin-bottom: 48px
            }

            .ee {
                font-size: 14px
            }

            .ef {
                line-height: 20px
            }

            .el {
                font-size: 13px
            }

            .em {
                padding: 5px 12px
            }

            .fg {
                display: flex
            }

            .fy {
                margin-bottom: 68px
            }

            .gc {
                max-width: 680px
            }

            .hm {
                font-size: 42px
            }

            .hn {
                margin-top: 1.19em
            }

            .ho {
                line-height: 52px
            }

            .hp {
                letter-spacing: -0.011em
            }

            .ie {
                font-size: 22px
            }

            .if {
                margin-top: 0.92em
            }

            .ig {
                line-height: 28px
            }

            .iq {
                align-items: center
            }

            .ks {
                border-top: solid 1px #F2F2F2
            }

            .kt {
                border-bottom: solid 1px #F2F2F2
            }

            .ku {
                margin: 32px 0 0
            }

            .kv {
                padding: 3px 8px
            }

            .le> * {
                margin-right: 24px
            }

            .lf> :last-child {
                margin-right: 0
            }

            .mf {
                margin-top: 0px
            }

            .mu {
                margin: 0
            }

            .nv {
                margin-top: 56px
            }

            .ox {
                font-size: 20px
            }

            .oy {
                margin-top: 2.14em
            }

            .oz {
                line-height: 32px
            }

            .pa {
                letter-spacing: -0.003em
            }

            .qc {
                font-size: 24px
            }

            .qd {
                margin-top: 1.25em
            }

            .qe {
                line-height: 30px
            }

            .qf {
                letter-spacing: -0.016em
            }

            .qs {
                margin-top: 1.72em
            }

            .qt {
                line-height: 24px
            }

            .qu {
                letter-spacing: 0
            }

            .ra {
                margin-top: 0.94em
            }

            .rf {
                margin-top: 1.95em
            }

            .rq {
                margin-top: 1.14em
            }

            .sp {
                margin-top: 32px
            }

            .ui {
                margin-bottom: 88px
            }

            .ut {
                display: inline-block
            }

            .uy {
                padding-top: 72px
            }

            .we {
                margin-top: 40px
            }
        </style>
        <style type="text/css" data-fela-rehydration="606" data-fela-type="RULE" media="all and (max-width: 1079.98px)">
            .e {
                display: none
            }

            .me {
                margin-top: 0px
            }

            .oe {
                margin-left: auto
            }

            .of {
                text-align: center
            }

            .us {
                display: inline-block
            }
        </style>
        <style type="text/css" data-fela-rehydration="606" data-fela-type="RULE" media="all and (max-width: 903.98px)">
            .f {
                display: none
            }

            .md {
                margin-top: 0px
            }

            .ur {
                display: inline-block
            }
        </style>
        <style type="text/css" data-fela-rehydration="606" data-fela-type="RULE" media="all and (max-width: 727.98px)">
            .g {
                display: none
            }

            .mb {
                margin-top: 0px
            }

            .mc {
                margin-right: 0px
            }

            .su {
                padding: 10px 12px 10px
            }

            .uq {
                display: inline-block
            }
        </style>
        <style type="text/css" data-fela-rehydration="606" data-fela-type="RULE" media="all and (max-width: 551.98px)">
            .h {
                display: none
            }

            .s {
                display: flex
            }

            .t {
                justify-content: space-between
            }

            .br {
                width: 24px
            }

            .cb {
                margin: 0 24px
            }

            .cq {
                height: 40px
            }

            .cx {
                margin-bottom: 44px
            }

            .dj {
                margin-bottom: 32px
            }

            .dw {
                font-size: 13px
            }

            .dx {
                line-height: 20px
            }

            .eg {
                padding: 0px 8px 1px
            }

            .fu {
                margin-bottom: 4px
            }

            .gw {
                font-size: 32px
            }

            .gx {
                margin-top: 1.01em
            }

            .gy {
                line-height: 38px
            }

            .gz {
                letter-spacing: -0.014em
            }

            .hs {
                font-size: 18px
            }

            .ht {
                margin-top: 0.79em
            }

            .hu {
                line-height: 24px
            }

            .im {
                align-items: flex-start
            }

            .jp {
                flex-direction: column
            }

            .js {
                margin-bottom: 2px
            }

            .kg {
                margin: 24px -24px 0
            }

            .kh {
                padding: 0
            }

            .kw> * {
                margin-right: 8px
            }

            .kx> :last-child {
                margin-right: 24px
            }

            .lo {
                margin-left: 0px
            }

            .lz {
                margin-top: 0px
            }

            .ma {
                margin-right: 0px
            }

            .mq {
                margin: 0
            }

            .na {
                border: 1px solid #F2F2F2
            }

            .nb {
                border-radius: 99em
            }

            .nc {
                padding: 0px 16px 0px 12px
            }

            .nd {
                height: 38px
            }

            .ne {
                align-items: center
            }

            .ng svg {
                margin-right: 8px
            }

            .nr {
                margin-top: 40px
            }

            .oj {
                margin-top: 1.56em
            }

            .ok {
                line-height: 28px
            }

            .ol {
                letter-spacing: -0.003em
            }

            .po {
                font-size: 20px
            }

            .pp {
                margin-top: 0.93em
            }

            .pq {
                letter-spacing: 0
            }

            .qi {
                font-size: 16px
            }

            .qj {
                margin-top: 1.23em
            }

            .qw {
                margin-top: 0.67em
            }

            .rb {
                margin-top: 1.2em
            }

            .rm {
                margin-top: 1.34em
            }

            .sl {
                margin-top: 24px
            }

            .ue {
                margin-bottom: 80px
            }

            .up {
                display: inline-block
            }

            .uu {
                padding-top: 48px
            }

            .wa {
                margin-top: 32px
            }

            .nf:hover {
                border-color: #E5E5E5
            }
        </style>
        <style type="text/css" data-fela-rehydration="606" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">
            .i {
                display: none
            }

            .bu {
                width: 64px
            }

            .ce {
                margin: 0 64px
            }

            .ct {
                height: 48px
            }

            .da {
                margin-bottom: 52px
            }

            .dm {
                margin-bottom: 48px
            }

            .ec {
                font-size: 14px
            }

            .ed {
                line-height: 20px
            }

            .ej {
                font-size: 13px
            }

            .ek {
                padding: 5px 12px
            }

            .ff {
                display: flex
            }

            .fx {
                margin-bottom: 68px
            }

            .gb {
                max-width: 680px
            }

            .hi {
                font-size: 42px
            }

            .hj {
                margin-top: 1.19em
            }

            .hk {
                line-height: 52px
            }

            .hl {
                letter-spacing: -0.011em
            }

            .ib {
                font-size: 22px
            }

            .ic {
                margin-top: 0.92em
            }

            .id {
                line-height: 28px
            }

            .ip {
                align-items: center
            }

            .ko {
                border-top: solid 1px #F2F2F2
            }

            .kp {
                border-bottom: solid 1px #F2F2F2
            }

            .kq {
                margin: 32px 0 0
            }

            .kr {
                padding: 3px 8px
            }

            .lc> * {
                margin-right: 24px
            }

            .ld> :last-child {
                margin-right: 0
            }

            .mt {
                margin: 0
            }

            .nu {
                margin-top: 56px
            }

            .ot {
                font-size: 20px
            }

            .ou {
                margin-top: 2.14em
            }

            .ov {
                line-height: 32px
            }

            .ow {
                letter-spacing: -0.003em
            }

            .py {
                font-size: 24px
            }

            .pz {
                margin-top: 1.25em
            }

            .qa {
                line-height: 30px
            }

            .qb {
                letter-spacing: -0.016em
            }

            .qp {
                margin-top: 1.72em
            }

            .qq {
                line-height: 24px
            }

            .qr {
                letter-spacing: 0
            }

            .qz {
                margin-top: 0.94em
            }

            .re {
                margin-top: 1.95em
            }

            .rp {
                margin-top: 1.14em
            }

            .so {
                margin-top: 32px
            }

            .uh {
                margin-bottom: 88px
            }

            .ux {
                padding-top: 72px
            }

            .wd {
                margin-top: 40px
            }
        </style>
        <style type="text/css" data-fela-rehydration="606" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">
            .j {
                display: none
            }

            .w {
                display: flex
            }

            .x {
                justify-content: space-between
            }

            .bt {
                width: 64px
            }

            .cd {
                margin: 0 48px
            }

            .cs {
                height: 48px
            }

            .cz {
                margin-bottom: 52px
            }

            .dl {
                margin-bottom: 48px
            }

            .ea {
                font-size: 13px
            }

            .eb {
                line-height: 20px
            }

            .ei {
                padding: 0px 8px 1px
            }

            .fw {
                margin-bottom: 68px
            }

            .ga {
                max-width: 680px
            }

            .he {
                font-size: 42px
            }

            .hf {
                margin-top: 1.19em
            }

            .hg {
                line-height: 52px
            }

            .hh {
                letter-spacing: -0.011em
            }

            .hy {
                font-size: 22px
            }

            .hz {
                margin-top: 0.92em
            }

            .ia {
                line-height: 28px
            }

            .io {
                align-items: center
            }

            .kk {
                border-top: solid 1px #F2F2F2
            }

            .kl {
                border-bottom: solid 1px #F2F2F2
            }

            .km {
                margin: 32px 0 0
            }

            .kn {
                padding: 3px 8px
            }

            .la> * {
                margin-right: 24px
            }

            .lb> :last-child {
                margin-right: 0
            }

            .ms {
                margin: 0
            }

            .nt {
                margin-top: 56px
            }

            .op {
                font-size: 20px
            }

            .oq {
                margin-top: 2.14em
            }

            .or {
                line-height: 32px
            }

            .os {
                letter-spacing: -0.003em
            }

            .pu {
                font-size: 24px
            }

            .pv {
                margin-top: 1.25em
            }

            .pw {
                line-height: 30px
            }

            .px {
                letter-spacing: -0.016em
            }

            .qm {
                margin-top: 1.72em
            }

            .qn {
                line-height: 24px
            }

            .qo {
                letter-spacing: 0
            }

            .qy {
                margin-top: 0.94em
            }

            .rd {
                margin-top: 1.95em
            }

            .ro {
                margin-top: 1.14em
            }

            .sn {
                margin-top: 32px
            }

            .ug {
                margin-bottom: 88px
            }

            .uw {
                padding-top: 72px
            }

            .wc {
                margin-top: 40px
            }
        </style>
        <style type="text/css" data-fela-rehydration="606" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">
            .k {
                display: none
            }

            .u {
                display: flex
            }

            .v {
                justify-content: space-between
            }

            .bs {
                width: 24px
            }

            .cc {
                margin: 0 24px
            }

            .cr {
                height: 40px
            }

            .cy {
                margin-bottom: 44px
            }

            .dk {
                margin-bottom: 32px
            }

            .dy {
                font-size: 13px
            }

            .dz {
                line-height: 20px
            }

            .eh {
                padding: 0px 8px 1px
            }

            .fv {
                margin-bottom: 4px
            }

            .ha {
                font-size: 32px
            }

            .hb {
                margin-top: 1.01em
            }

            .hc {
                line-height: 38px
            }

            .hd {
                letter-spacing: -0.014em
            }

            .hv {
                font-size: 18px
            }

            .hw {
                margin-top: 0.79em
            }

            .hx {
                line-height: 24px
            }

            .in {
                align-items: flex-start
            }

            .jq {
                flex-direction: column
            }

            .jt {
                margin-bottom: 2px
            }

            .ki {
                margin: 24px 0 0
            }

            .kj {
                padding: 0
            }

            .ky> * {
                margin-right: 8px
            }

            .kz> :last-child {
                margin-right: 8px
            }

            .lp {
                margin-left: 0px
            }

            .mr {
                margin: 0
            }

            .nh {
                border: 1px solid #F2F2F2
            }

            .ni {
                border-radius: 99em
            }

            .nj {
                padding: 0px 16px 0px 12px
            }

            .nk {
                height: 38px
            }

            .nl {
                align-items: center
            }

            .nn svg {
                margin-right: 8px
            }

            .ns {
                margin-top: 40px
            }

            .om {
                margin-top: 1.56em
            }

            .on {
                line-height: 28px
            }

            .oo {
                letter-spacing: -0.003em
            }

            .pr {
                font-size: 20px
            }

            .ps {
                margin-top: 0.93em
            }

            .pt {
                letter-spacing: 0
            }

            .qk {
                font-size: 16px
            }

            .ql {
                margin-top: 1.23em
            }

            .qx {
                margin-top: 0.67em
            }

            .rc {
                margin-top: 1.2em
            }

            .rn {
                margin-top: 1.34em
            }

            .sm {
                margin-top: 24px
            }

            .uf {
                margin-bottom: 80px
            }

            .uv {
                padding-top: 48px
            }

            .wb {
                margin-top: 32px
            }

            .nm:hover {
                border-color: #E5E5E5
            }
        </style>
        <style type="text/css" data-fela-rehydration="606" data-fela-type="RULE" media="print">
            .un {
                display: none
            }
        </style>
        <style type="text/css" data-fela-rehydration="606" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">
            .kd {
                max-height: none
            }
        </style>
    </head>
    <body>
        <div id="root">
            <div class="a b c">
                <div class="d e f g h i j k"></div>
                <div class="l c">
                    <div class="l m n o c">
                        <div class="p q r s t u v w x i d y z">
                            <a class="dt ag du be ak b am an ao ap aq ar as at s u w i d q dv z" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa34a51b93873&amp;%7Efeature=LoOpenInAppButton&amp;%7Echannel=ShowPostUnderCollection&amp;source=---two_column_layout_nav----------------------------------" rel="noopener follow">
                                Open in app
                                <svg width="10" height="10" viewBox="0 0 10 10" fill="none" class="ds">
                                    <path d="M.98 8.48a.37.37 0 1 0 .54.54l-.54-.54zm7.77-7.23h.38c0-.2-.17-.38-.38-.38v.38zM8.37 6.5a.37.37 0 1 0 .76 0h-.76zM3.5.87a.37.37 0 1 0 0 .76V.88zM1.52 9.03l7.5-7.5-.54-.54-7.5 7.5.54.54zm6.86-7.77V6.5h.74V1.25h-.74zm-4.88.38h5.25V.88H3.5v.74z" fill="currentColor"></path>
                                </svg>
                            </a>
                            <!-- <div class="ab q">
                                <p class="be b dw dx dy dz ea eb ec ed ee ef dt">
                                    <span>
                                        <a class="be b dw dx eg dy dz eh ea eb ei ej ed ek el ef em eo ep eq er es et eu ev ew ex ey ez fa fb fc bl fd fe" data-testid="headerSignUpButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-math-behind-neural-networks-a34a51b93873&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign up</a>
                                    </span>
                                </p>
                                <div class="aw l">
                                    <p class="be b dw dx dy dz ea eb ec ed ee ef dt">
                                        <span>
                                            <a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSignInButton" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-math-behind-neural-networks-a34a51b93873&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign in</a>
                                        </span>
                                    </p>
                                </div>
                            </div> -->
                        </div>
 
                    </div>
                    <div class="l">
                        <div class="fu fv fw fx fy l">
                            <div class="ab ca">
                                <div class="ch bg fz ga gb gc"></div>
                            </div>
                            <article>
                                <div class="l">
                                    <div class="l">
                                        <span class="l"></span>
                                        <section>
                                            <div>
                                                <div class="fr gi gj gk gl gm"></div>
                                                <div class="gn go gp gq gr">
                                                    <div class="ab ca">
                                                        <div class="ch bg fz ga gb gc">
                                                            <div>
                                                                <h1 id="28e6" class="pw-post-title gs gt gu be gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho hp hq bj" data-testid="storyTitle">The Math Behind Neural Networks</h1>
                                                            </div>
                                                            <div>
                                                                <h2 id="e563" class="pw-subtitle-paragraph hr gt gu be b hs ht hu hv hw hx hy hz ia ib ic id ie if ig cp dt">Dive into Neural Networks, the backbone of modern AI, understand its mathematics, implement it from scratch, and explore its applications</h2>
                                                                <div class="ih ii ij ik il">
                                                                    <div class="speechify-ignore ab co">
                                                                        <div class="speechify-ignore bg l">
                                                                            <div class="im in io ip iq ab">
                                                                                <div>
                                                                                    <div class="ab ir">
                                                                                        <a href="https://medium.com/@cristianleo120?source=post_page-----a34a51b93873--------------------------------" rel="noopener follow">
                                                                                            <div>
                                                                                                <div class="bl" aria-hidden="false">
                                                                                                    <div class="l is it bx iu iv">
                                                                                                        <div class="l fi">
                                                                                                            <img alt="Cristian Leo" class="l fc bx dc dd cw" src="https://miro.medium.com/v2/da:true/resize:fill:88:88/0*vXUpsKuv7A7DlqP0" width="44" height="44" loading="lazy" data-testid="authorPhoto"/>
                                                                                                            <div class="iw bx l dc dd fr n ix fs"></div>
                                                                                                        </div>
                                                                                                    </div>
                                                                                                </div>
                                                                                            </div>
                                                                                        </a>
                                                                                        <a href="https://towardsdatascience.com/?source=post_page-----a34a51b93873--------------------------------" rel="noopener follow">
                                                                                            <div class="iy ab fi">
                                                                                                <div>
                                                                                                    <div class="bl" aria-hidden="false">
                                                                                                        <div class="l iz ja bx iu jb">
                                                                                                            <div class="l fi">
                                                                                                                <img alt="Towards Data Science" class="l fc bx bq jc cw" src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg" width="24" height="24" loading="lazy" data-testid="publicationPhoto"/>
                                                                                                                <div class="iw bx l bq jc fr n ix fs"></div>
                                                                                                            </div>
                                                                                                        </div>
                                                                                                    </div>
                                                                                                </div>
                                                                                            </div>
                                                                                        </a>
                                                                                    </div>
                                                                                </div>
                                                                                <div class="bm bg l">
                                                                                    <div class="ab">
                                                                                        <div style="flex:1">
                                                                                            <span class="be b bf z bj">
                                                                                                <div class="jd ab q">
                                                                                                    <div class="ab q je">
                                                                                                        <div class="ab q">
                                                                                                            <div>
                                                                                                                <div class="bl" aria-hidden="false">
                                                                                                                    <p class="be b jf jg bj">
                                                                                                                        <a class="af ag ah ai aj ak al am an ao ap aq ar jh" data-testid="authorName" href="https://medium.com/@cristianleo120?source=post_page-----a34a51b93873--------------------------------" rel="noopener follow">Cristian Leo</a>
                                                                                                                    </p>
                                                                                                                </div>
                                                                                                            </div>
                                                                                                        </div>
                                                                                                        <span class="ji jj" aria-hidden="true">
                                                                                                            <span class="be b bf z dt"></span>
                                                                                                        </span>
                                                                                                        <p class="be b jf jg dt">
                                                                                                            <span>
                                                                                                                <a class="jk jl ah ai aj ak al am an ao ap aq ar ew jm jn" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc24a3d106811&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-math-behind-neural-networks-a34a51b93873&amp;user=Cristian+Leo&amp;userId=c24a3d106811&amp;source=post_page-c24a3d106811----a34a51b93873---------------------post_header-----------" rel="noopener follow">Follow</a>
                                                                                                            </span>
                                                                                                        </p>
                                                                                                    </div>
                                                                                                </div>
                                                                                            </span>
                                                                                        </div>
                                                                                    </div>
                                                                                    <div class="l jo">
                                                                                        <span class="be b bf z dt">
                                                                                            <div class="ab cm jp jq jr">
                                                                                                <div class="js jt ab">
                                                                                                    <div class="be b bf z dt ab ju">
                                                                                                        <span class="jv l jo">Published in</span>
                                                                                                        <div>
                                                                                                            <div class="l" aria-hidden="false">
                                                                                                                <a class="af ag ah ai aj ak al am an ao ap aq ar jh ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page-----a34a51b93873--------------------------------" rel="noopener follow">
                                                                                                                    <p class="be b bf z jw jx jy jz ka kb kc kd bj">Towards Data Science</p>
                                                                                                                </a>
                                                                                                            </div>
                                                                                                        </div>
                                                                                                    </div>
                                                                                                    <div class="h k">
                                                                                                        <span class="ji jj" aria-hidden="true">
                                                                                                            <span class="be b bf z dt"></span>
                                                                                                        </span>
                                                                                                    </div>
                                                                                                </div>
                                                                                
                                                                                            </div>
                                                                                        </span>
                                                                                    </div>
                                                                                </div>
                                                                            </div>
                                                                            <div class="ab co kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv">
                                                                                <div class="h k w ff fg q">
                                                                                    <div class="ll l">
                                                                                        <div class="ab q lm ln">
                                                                                            <div class="pw-multi-vote-icon fi jv lo lp lq">
                                                                                                <span>
                                                                                                    <a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa34a51b93873&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-math-behind-neural-networks-a34a51b93873&amp;user=Cristian+Leo&amp;userId=c24a3d106811&amp;source=-----a34a51b93873---------------------clap_footer-----------" rel="noopener follow">
                                                                                                        <div>
                                                                                                            <div class="bl" aria-hidden="false">
                                                                                                                <div class="lr ao ls lt lu lv am lw lx ly lq">
                                                                                                                    <svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap">
                                                                                                                        <path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path>
                                                                                                                    </svg>
                                                                                                                </div>
                                                                                                            </div>
                                                                                                        </div>
                                                                                                    </a>
                                                                                                </span>
                                                                                            </div>
                                                                                            <div class="pw-multi-vote-count l lz ma mb mc md me mf">
                                                                                                <p class="be b du z dt">
                                                                                                    <span class="mg">--</span>
                                                                                                </p>
                                                                                            </div>
                                                                                        </div>
                                                                                    </div>
                                                                                    <div>
                                                                                        <div class="bl" aria-hidden="false">
                                                                                            <button class="ao lr mj mk ab q fj ml mm" aria-label="responses">
                                                                                                <svg width="24" height="24" viewBox="0 0 24 24" class="mi">
                                                                                                    <path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path>
                                                                                                </svg>
                                                                                                <p class="be b du z dt">
                                                                                                    <span class="pw-responses-count mh mi">8</span>
                                                                                                </p>
                                                                                            </button>
                                                                                        </div>
                                                                                    </div>
                                                                                </div>
                                                                                <div class="ab q kw kx ky kz la lb lc ld le lf lg lh li lj lk">
                                                                                    <div class="mn k j i d"></div>
                                                                                    <div class="h k">
                                                                                        <div>
                                                                                            <div class="bl" aria-hidden="false">
                                                                                                <span>
                                                                                                    <a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa34a51b93873&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-math-behind-neural-networks-a34a51b93873&amp;source=-----a34a51b93873---------------------bookmark_footer-----------" rel="noopener follow">
                                                                                                        <svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="dt mo" aria-label="Add to list bookmark button">
                                                                                                            <path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="currentColor"></path>
                                                                                                        </svg>
                                                                                                    </a>
                                                                                                </span>
                                                                                            </div>
                                                                                        </div>
                                                                                    </div>
                                                                                    <div class="fc mp cm">
                                                                                        <div class="l ae">
                                                                                            <div class="ab ca">
                                                                                                <div class="mq mr ms mt mu mv ch bg">
                                                                                                    <div class="ab">
                                                                                                        <div class="bl bg" aria-hidden="false">
                                                                                                            <div>
                                                                                                                <div class="bl" aria-hidden="false">
                                                                                                                    <button aria-label="Listen" data-testid="audioPlayButton" class="af fj ah ai aj ak al mw an ao ap ew mx my mm mz na nb nc nd s ne nf ng nh ni nj nk u nl nm nn">
                                                                                                                        <svg width="24" height="24" viewBox="0 0 24 24" fill="none">
                                                                                                                            <path fill-rule="evenodd" clip-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0zm9-10a10 10 0 1 0 0 20 10 10 0 0 0 0-20zm3.38 10.42l-4.6 3.06a.5.5 0 0 1-.78-.41V8.93c0-.4.45-.63.78-.41l4.6 3.06c.3.2.3.64 0 .84z" fill="currentColor"></path>
                                                                                                                        </svg>
                                                                                                                        <div class="j i d">
                                                                                                                            <p class="be b bf z dt">Listen</p>
                                                                                                                        </div>
                                                                                                                    </button>
                                                                                                                </div>
                                                                                                            </div>
                                                                                                        </div>
                                                                                                    </div>
                                                                                                </div>
                                                                                            </div>
                                                                                        </div>
                                                                                    </div>
                                                                                    <div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu">
                                                                                        <div>
                                                                                            <div class="bl" aria-hidden="false">
                                                                                                <button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af fj ah ai aj ak al mw an ao ap ew mx my mm mz na nb nc nd s ne nf ng nh ni nj nk u nl nm nn">
                                                                                                    <svg width="24" height="24" viewBox="0 0 24 24" fill="none">
                                                                                                        <path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path>
                                                                                                    </svg>
                                                                                                    <div class="j i d">
                                                                                                        <p class="be b bf z dt">Share</p>
                                                                                                    </div>
                                                                                                </button>
                                                                                            </div>
                                                                                        </div>
                                                                                    </div>
                                                                                </div>
                                                                            </div>
                                                                        </div>
                                                                    </div>
                                                                </div>
                                                            </div>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div role="button" tabindex="0" class="nx ny fi nz bg oa">
                                                                    <div class="no np nq">
                                                                        <picture>
                                                                            <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*lYCxlGeLK2scQE2L 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*lYCxlGeLK2scQE2L 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*lYCxlGeLK2scQE2L 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*lYCxlGeLK2scQE2L 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*lYCxlGeLK2scQE2L 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*lYCxlGeLK2scQE2L 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lYCxlGeLK2scQE2L 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/>
                                                                            <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*lYCxlGeLK2scQE2L 640w, https://miro.medium.com/v2/resize:fit:720/0*lYCxlGeLK2scQE2L 720w, https://miro.medium.com/v2/resize:fit:750/0*lYCxlGeLK2scQE2L 750w, https://miro.medium.com/v2/resize:fit:786/0*lYCxlGeLK2scQE2L 786w, https://miro.medium.com/v2/resize:fit:828/0*lYCxlGeLK2scQE2L 828w, https://miro.medium.com/v2/resize:fit:1100/0*lYCxlGeLK2scQE2L 1100w, https://miro.medium.com/v2/resize:fit:1400/0*lYCxlGeLK2scQE2L 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/>
                                                                            <img alt="" class="bg mv ob c" width="700" height="400" loading="eager" role="presentation"/>
                                                                        </picture>
                                                                    </div>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">Image by DALL-E</figcaption>
                                                            </figure>
                                                            <p id="f7e1" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Neural networks are at the core of artificial intelligence (AI), fueling a variety of applications from spotting objects in photos to translating languages. In this article, well dive into what neural networks are, how they work, and why theyre a big deal in our technology-driven world today.</p>
                                                        </div>
                                                    </div>
                                                </div>
                                                <div class="ab ca pc pd pe pf" role="separator">
                                                    <span class="pg bx bl ph pi pj"></span>
                                                    <span class="pg bx bl ph pi pj"></span>
                                                    <span class="pg bx bl ph pi"></span>
                                                </div>
                                                <div class="gn go gp gq gr">
                                                    <div class="ab ca">
                                                        <div class="ch bg fz ga gb gc">
                                                            <p id="dea9" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">Index</strong>
                                                                <br/>
                                                                <strong class="oi gv"> </strong>
                                                                <a class="af pk" href="#2200" rel="noopener ugc nofollow">
                                                                    <strong class="oi gv">1: Understanding the Basics</strong>
                                                                </a>
                                                                <br/>
                                                                 <a class="af pk" href="#2077" rel="noopener ugc nofollow">1.1: What are Neural Networks?</a>
                                                                <br/>
                                                                 <a class="af pk" href="#f8c6" rel="noopener ugc nofollow">1.2: Types of Neural Networks</a>
                                                            </p>
                                                            <p id="215a" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv"> </strong>
                                                                <a class="af pk" href="#1208" rel="noopener ugc nofollow">
                                                                    <strong class="oi gv">2: The Architecture of Neural Networks</strong>
                                                                </a>
                                                                <br/>
                                                                 <a class="af pk" href="#b18e" rel="noopener ugc nofollow">2.1: The Structure of a Neuron</a>
                                                                <br/>
                                                                 <a class="af pk" href="#ab12" rel="noopener ugc nofollow">2.2: Layers</a>
                                                                <br/>
                                                                 <a class="af pk" href="#69b9" rel="noopener ugc nofollow">2.3: The Role of Layers in Learning</a>
                                                            </p>
                                                            <p id="5dd2" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv"> </strong>
                                                                <a class="af pk" href="#3bb7" rel="noopener ugc nofollow">
                                                                    <strong class="oi gv">3: The Mathematics of Neural Networks</strong>
                                                                </a>
                                                                <br/>
                                                                 <a class="af pk" href="#665d" rel="noopener ugc nofollow">3.1: Weighted Sum</a>
                                                                <br/>
                                                                 <a class="af pk" href="#e015" rel="noopener ugc nofollow">3.2: Activation Functions</a>
                                                                <br/>
                                                                 <a class="af pk" href="#03fd" rel="noopener ugc nofollow">3.3: Backpropagation: The Core of Neural Learning</a>
                                                                <br/>
                                                                 <a class="af pk" href="#d519" rel="noopener ugc nofollow">3.4: Step by Step example</a>
                                                                <br/>
                                                                 <a class="af pk" href="#e495" rel="noopener ugc nofollow">3.5: Improvements</a>
                                                            </p>
                                                            <p id="6aa4" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv"> </strong>
                                                                <a class="af pk" href="#cd9e" rel="noopener ugc nofollow">
                                                                    <strong class="oi gv">4: Implementing Neural Networks</strong>
                                                                </a>
                                                                <br/>
                                                                 <a class="af pk" href="#7f0a" rel="noopener ugc nofollow">4.1: Building a Simple Neural Network in Python</a>
                                                                <br/>
                                                                 <a class="af pk" href="#f6d9" rel="noopener ugc nofollow">4.2: Utilizing Libraries for Neural Network Implementation (TensorFlow)</a>
                                                            </p>
                                                            <p id="be55" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv"> </strong>
                                                                <a class="af pk" href="#2a21" rel="noopener ugc nofollow">
                                                                    <strong class="oi gv">5: Challenges</strong>
                                                                </a>
                                                                <br/>
                                                                 <a class="af pk" href="#2a8a" rel="noopener ugc nofollow">5.1: Overcoming Overfitting</a>
                                                            </p>
                                                            <p id="503a" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv"> </strong>
                                                                <a class="af pk" href="#f035" rel="noopener ugc nofollow">
                                                                    <strong class="oi gv">6: Conclusion</strong>
                                                                </a>
                                                            </p>
                                                        </div>
                                                    </div>
                                                </div>
                                                <div class="ab ca pc pd pe pf" role="separator">
                                                    <span class="pg bx bl ph pi pj"></span>
                                                    <span class="pg bx bl ph pi pj"></span>
                                                    <span class="pg bx bl ph pi"></span>
                                                </div>
                                                <div class="gn go gp gq gr">
                                                    <div class="ab ca">
                                                        <div class="ch bg fz ga gb gc">
                                                            <h1 id="2200" class="pl pm gu be pn po pp hu pq pr ps hx pt pu pv pw px py pz qa qb qc qd qe qf qg bj">1: Understanding the Basics</h1>
                                                            <h2 id="2077" class="qh pm gu be pn qi qj dx pq qk ql dz pt op qm qn qo ot qp qq qr ox qs qt qu qv bj">1.1: What are Neural Networks?</h2>
                                                            <p id="cd6a" class="pw-post-body-paragraph og oh gu oi b hs qw ok ol hv qx on oo op qy or os ot qz ov ow ox ra oz pa pb gn bj">Neural networks are a cool blend of biology and computer science, inspired by our brains setup to tackle complicated computing tasks. Essentially, theyre algorithms designed to spot patterns and make sense of sensory data, which lets them do a ton of stuff like recognizing faces, understanding spoken words, making predictions, and understanding natural language.</p>
                                                            <p id="ee3e" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">The Biological Inspiration</strong>
                                                            </p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div role="button" tabindex="0" class="nx ny fi nz bg oa">
                                                                    <div class="no np nq">
                                                                        <picture>
                                                                            <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*RmTRa3vrNVFBZypb 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*RmTRa3vrNVFBZypb 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*RmTRa3vrNVFBZypb 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*RmTRa3vrNVFBZypb 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*RmTRa3vrNVFBZypb 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*RmTRa3vrNVFBZypb 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RmTRa3vrNVFBZypb 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/>
                                                                            <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*RmTRa3vrNVFBZypb 640w, https://miro.medium.com/v2/resize:fit:720/0*RmTRa3vrNVFBZypb 720w, https://miro.medium.com/v2/resize:fit:750/0*RmTRa3vrNVFBZypb 750w, https://miro.medium.com/v2/resize:fit:786/0*RmTRa3vrNVFBZypb 786w, https://miro.medium.com/v2/resize:fit:828/0*RmTRa3vrNVFBZypb 828w, https://miro.medium.com/v2/resize:fit:1100/0*RmTRa3vrNVFBZypb 1100w, https://miro.medium.com/v2/resize:fit:1400/0*RmTRa3vrNVFBZypb 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/>
                                                                            <img alt="" class="bg mv ob c" width="700" height="400" loading="lazy" role="presentation"/>
                                                                        </picture>
                                                                    </div>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">Image by DALL-E</figcaption>
                                                            </figure>
                                                            <p id="716f" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Our brains have about 86 billion neurons, all linked up in a complex network. These neurons chat through connections called synapses, where signals can get stronger or weaker, influencing the message passed along. This is the foundation of how we learn and remember things.</p>
                                                            <p id="c002" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Artificial neural networks take a page from this book, using digital neurons or nodes that connect in layers. Youve got input layers that take in data, hidden layers that chew on this data, and output layers that spit out the result. As the network gets fed more data, it adjusts the connection strengths (or weights) to learn, kind of like how our brains synapses strengthen or weaken.</p>
                                                            <p id="ae1c" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">
                                                                    From Perceptrons to Deep Learning<br/>
                                                                </strong>
                                                                Neural networks started with something called a perceptron in 1958, thanks to Frank Rosenblatt. This was a basic neural network meant for simple yes-or-no-type tasks. From there, we built more complex networks, like multi-layer perceptrons (MLPs), which can understand more complicated data relationships thanks to having one or more hidden layers.
                                                            </p>
                                                            <p id="e14e" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Then came deep learning, which is all about neural networks with lots of layers. These deep neural networks are capable of learning from huge piles of data, and theyre behind a lot of the AI breakthroughs we hear about, from beating human Go players to powering self-driving cars.</p>
                                                            <p id="09ed" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">
                                                                    Understanding Through Patterns<br/>
                                                                </strong>
                                                                One of the biggest strengths of neural networks is their ability to learn patterns in data without being directly programmed for specific tasks. This process, called training, lets neural networks pick up on general trends and make predictions or decisions based on what theyve learned.
                                                            </p>
                                                            <p id="a024" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Thanks to this capability, neural networks are super versatile and can be used for a wide array of applications, from image recognition to language translation, to forecasting stock market trends. Theyre proving that tasks once thought to require human intelligence can now be tackled by AI.</p>
                                                            <h2 id="f8c6" class="qh pm gu be pn qi qj dx pq qk ql dz pt op qm qn qo ot qp qq qr ox qs qt qu qv bj">1.2: Types of Neural Networks</h2>
                                                            <p id="54dc" class="pw-post-body-paragraph og oh gu oi b hs qw ok ol hv qx on oo op qy or os ot qz ov ow ox ra oz pa pb gn bj">Before diving into their structure and math, lets take a look at the most popular types of Neural Networks we may find today. This will give us a better understanding of their potential and capabilities. I will try to cover all of them in future articles, so make sure to subscribe!</p>
                                                            <p id="933e" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">
                                                                    Feedforward Neural Networks (FNN)<br/>
                                                                </strong>
                                                                Starting with the basics, the Feedforward Neural Network is the simplest type. Its like a one-way street for data  information travels straight from the input, through any hidden layers, and out the other side to the output. These networks are the go-to for simple predictions and sorting things into categories.
                                                            </p>
                                                            <p id="b6ab" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">
                                                                    Convolutional Neural Networks (CNN)<br/>
                                                                </strong>
                                                                CNNs are the big guns in the world of computer vision. Theyve got a knack for picking up on the spatial patterns in images, thanks to their specialized layers. This ability makes them stars at recognizing images, spotting objects within them, and classifying what they see. Theyre the reason your phone can tell a dog from a cat in photos.
                                                            </p>
                                                            <p id="82ca" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">
                                                                    Recurrent Neural Networks (RNN)<br/>
                                                                </strong>
                                                                RNNs have a memory of sorts, making them great for anything involving sequences of data, like sentences, DNA sequences, handwriting, or stock market trends. They loop information back around, allowing them to remember previous inputs in the sequence. This makes them ace at tasks like predicting the next word in a sentence or understanding spoken language.
                                                            </p>
                                                            <p id="4a07" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">
                                                                    Long Short-Term Memory Networks (LSTM)<br/>
                                                                </strong>
                                                                LSTMs are a special breed of RNNs built to remember things for longer stretches. Theyre designed to solve the problem of RNNs forgetting stuff over long sequences. If youre dealing with complex tasks that need to hold onto information for a long time, like translating paragraphs or predicting what happens next in a TV series, LSTMs are your go-to.
                                                            </p>
                                                            <p id="6da6" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">
                                                                    Generative Adversarial Networks (GAN)<br/>
                                                                </strong>
                                                                Imagine two AIs in a cat-and-mouse game: one generates fake data (like images), and the other tries to catch whats fake and whats real. Thats a GAN. This setup allows GANs to create incredibly realistic images, music, text, and more. Theyre the artists of the neural network world, generating new, realistic data from scratch.
                                                            </p>
                                                            <h1 id="1208" class="pl pm gu be pn po rb hu pq pr rc hx pt pu rd pw px py re qa qb qc rf qe qf qg bj">2: The Architecture of Neural Networks</h1>
                                                            <p id="4fc7" class="pw-post-body-paragraph og oh gu oi b hs qw ok ol hv qx on oo op qy or os ot qz ov ow ox ra oz pa pb gn bj">At the core of neural networks are what we call neurons or nodes, inspired by the nerve cells in our brains. These artificial neurons are the workhorses that handle the heavy lifting of receiving, crunching, and passing along information. Lets dive into how these neurons are built.</p>
                                                            <h2 id="b18e" class="qh pm gu be pn qi qj dx pq qk ql dz pt op qm qn qo ot qp qq qr ox qs qt qu qv bj">
                                                                <strong class="al">2.1: The Structure of a Neuron</strong>
                                                            </h2>
                                                            <p id="cbcf" class="pw-post-body-paragraph og oh gu oi b hs qw ok ol hv qx on oo op qy or os ot qz ov ow ox ra oz pa pb gn bj">A neuron gets its input either directly from the data were interested in or from the outputs of other neurons. These inputs are like a list, with each item on the list representing a different characteristic of the data.</p>
                                                            <p id="7224" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">For each input, the neuron does a little math: it multiplies the input by a weight and then adds a bias. Think of weights as the neurons way of deciding how important an input is, and bias as a tweak to make sure the neurons output fits just right. During the networks training, it adjusts these weights and biases to get better at its job.</p>
                                                            <p id="8711" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Next, the neuron sums up all these weighted inputs and biases and runs the total through a special function called an activation function. This step is where the magic happens, allowing the neuron to tackle complex patterns by bending and stretching the data in nonlinear ways. Popular choices for this function are ReLU, Sigmoid, and Tanh, each with its way of tweaking the data.</p>
                                                            <h2 id="ab12" class="qh pm gu be pn qi qj dx pq qk ql dz pt op qm qn qo ot qp qq qr ox qs qt qu qv bj">
                                                                <strong class="al">2.2: Layers</strong>
                                                            </h2>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np rg">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*ukHeC6BHZVrwKwTEtdu1dQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*ukHeC6BHZVrwKwTEtdu1dQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*ukHeC6BHZVrwKwTEtdu1dQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*ukHeC6BHZVrwKwTEtdu1dQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*ukHeC6BHZVrwKwTEtdu1dQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ukHeC6BHZVrwKwTEtdu1dQ.png 1100w, https://miro.medium.com/v2/resize:fit:1320/format:webp/1*ukHeC6BHZVrwKwTEtdu1dQ.png 1320w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 660px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*ukHeC6BHZVrwKwTEtdu1dQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*ukHeC6BHZVrwKwTEtdu1dQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*ukHeC6BHZVrwKwTEtdu1dQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*ukHeC6BHZVrwKwTEtdu1dQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*ukHeC6BHZVrwKwTEtdu1dQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*ukHeC6BHZVrwKwTEtdu1dQ.png 1100w, https://miro.medium.com/v2/resize:fit:1320/1*ukHeC6BHZVrwKwTEtdu1dQ.png 1320w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 660px"/>
                                                                        <img alt="" class="bg mv ob c" width="660" height="522" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">FNN Architecture with 3 Layers  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="5c73" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Neural networks are structured in layers, sort of like a layered cake, with each layer made up of multiple neurons. The way these layers stack up forms the networks architecture:</p>
                                                            <p id="e795" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">Input Layer</strong>
                                                                <br/>This is where the data enters the network. Each neuron here corresponds to one feature of the data. In the image above the input layer is the first layer on the left holding two nodes.
                                                            </p>
                                                            <p id="6918" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">Hidden Layers</strong>
                                                                <br/>These are the layers sandwiched between the input and output, as we can see from the image above. You might have just one or a bunch of these hidden layers, doing the grunt work of computations and transformations. The more layers (and neurons in each layer) you have, the more intricate patterns the network can learn. But, this also means more computing power is needed and a higher chance of the network getting too caught up in the training data, a problem known as overfitting.
                                                            </p>
                                                            <p id="1352" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">
                                                                    Output Layer<br/>
                                                                </strong>
                                                                This is the networks final stop, where it spits out the results. Depending on the task, like if its classifying data, this layer might have a neuron for each category, using something like the softmax function to give probabilities for each category. In the image above, the last layer holds only one node, suggesting that the is used for a regression task.
                                                            </p>
                                                            <h2 id="69b9" class="qh pm gu be pn qi qj dx pq qk ql dz pt op qm qn qo ot qp qq qr ox qs qt qu qv bj">
                                                                <strong class="al">2.3: The Role of Layers in Learning</strong>
                                                            </h2>
                                                            <p id="a2c2" class="pw-post-body-paragraph og oh gu oi b hs qw ok ol hv qx on oo op qy or os ot qz ov ow ox ra oz pa pb gn bj">The hidden layers are the networks feature detectives. As data moves through these layers, the network gets better at spotting and combining input features, layering them into a more complex understanding of the data.</p>
                                                            <p id="4919" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">With each layer the data passes through, the network can pick up on more intricate patterns. Early layers might learn basic stuff like shapes or textures, while deeper layers get the hang of more complex ideas, like recognizing objects or faces in pictures.</p>
                                                            <h1 id="3bb7" class="pl pm gu be pn po rb hu pq pr rc hx pt pu rd pw px py re qa qb qc rf qe qf qg bj">3: The Mathematics of Neural Networks</h1>
                                                            <h2 id="665d" class="qh pm gu be pn qi qj dx pq qk ql dz pt op qm qn qo ot qp qq qr ox qs qt qu qv bj">3.1: Weighted Sum</h2>
                                                            <p id="9d7a" class="pw-post-body-paragraph og oh gu oi b hs qw ok ol hv qx on oo op qy or os ot qz ov ow ox ra oz pa pb gn bj">The first step in the neural computation process involves aggregating the inputs to a neuron, each multiplied by their respective weights, and then adding a bias term. This operation is known as the weighted sum or linear combination. Mathematically, it is expressed as:</p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np rh">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*tt1rI7VxYc_kkyalKMmIIg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*tt1rI7VxYc_kkyalKMmIIg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*tt1rI7VxYc_kkyalKMmIIg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*tt1rI7VxYc_kkyalKMmIIg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*tt1rI7VxYc_kkyalKMmIIg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*tt1rI7VxYc_kkyalKMmIIg.png 1100w, https://miro.medium.com/v2/resize:fit:662/format:webp/1*tt1rI7VxYc_kkyalKMmIIg.png 662w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 331px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*tt1rI7VxYc_kkyalKMmIIg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*tt1rI7VxYc_kkyalKMmIIg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*tt1rI7VxYc_kkyalKMmIIg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*tt1rI7VxYc_kkyalKMmIIg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*tt1rI7VxYc_kkyalKMmIIg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*tt1rI7VxYc_kkyalKMmIIg.png 1100w, https://miro.medium.com/v2/resize:fit:662/1*tt1rI7VxYc_kkyalKMmIIg.png 662w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 331px"/>
                                                                        <img alt="" class="bg mv ob c" width="331" height="46" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">NNs Weighted Sum Formula  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="a67e" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">where:</p>
                                                            <ul class="">
                                                                <li id="73f3" class="og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb ri rj rk bj">
                                                                    <em class="rl">z</em>
                                                                    is the weighted sum,
                                                                </li>
                                                                <li id="1a89" class="og oh gu oi b hs rm ok ol hv rn on oo op ro or os ot rp ov ow ox rq oz pa pb ri rj rk bj">
                                                                    <em class="rl">wi</em>
                                                                     represents the weight associated with the <em class="rl">i</em>
                                                                    -th input,
                                                                </li>
                                                                <li id="63c6" class="og oh gu oi b hs rm ok ol hv rn on oo op ro or os ot rp ov ow ox rq oz pa pb ri rj rk bj">
                                                                    <em class="rl">xi</em>
                                                                     is the <em class="rl">i</em>
                                                                    -th input to the neuron,
                                                                </li>
                                                                <li id="2f9b" class="og oh gu oi b hs rm ok ol hv rn on oo op ro or os ot rp ov ow ox rq oz pa pb ri rj rk bj">
                                                                    <em class="rl">b</em>
                                                                    is the bias term, a unique parameter that allows adjusting the output along with the weighted sum.
                                                                </li>
                                                            </ul>
                                                            <p id="25e4" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">The weighted sum is crucial because it constitutes the raw input signal to a neuron before any non-linear transformation. It allows the network to perform a linear transformation of the inputs, adjusting the importance (weight) of each input in the neurons output.</p>
                                                            <h2 id="e015" class="qh pm gu be pn qi qj dx pq qk ql dz pt op qm qn qo ot qp qq qr ox qs qt qu qv bj">3.2: Activation Functions</h2>
                                                            <p id="0960" class="pw-post-body-paragraph og oh gu oi b hs qw ok ol hv qx on oo op qy or os ot qz ov ow ox ra oz pa pb gn bj">As we said before, activation functions play a pivotal role in determining the output of a neural network. They are mathematical equations that determine whether a neuron should be activated or not. Activation functions introduce non-linear properties to the network, enabling it to learn complex data patterns and perform tasks beyond mere linear classification, which is essential for deep learning models. Here, we delve into several key types of activation functions and their significance:</p>
                                                            <p id="f86f" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">Sigmoid Activation Function</strong>
                                                            </p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np rr">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*MXY5i10BeQAxjF8gle0_aA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*MXY5i10BeQAxjF8gle0_aA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*MXY5i10BeQAxjF8gle0_aA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*MXY5i10BeQAxjF8gle0_aA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*MXY5i10BeQAxjF8gle0_aA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*MXY5i10BeQAxjF8gle0_aA.png 1100w, https://miro.medium.com/v2/resize:fit:840/format:webp/1*MXY5i10BeQAxjF8gle0_aA.png 840w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 420px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*MXY5i10BeQAxjF8gle0_aA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*MXY5i10BeQAxjF8gle0_aA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*MXY5i10BeQAxjF8gle0_aA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*MXY5i10BeQAxjF8gle0_aA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*MXY5i10BeQAxjF8gle0_aA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*MXY5i10BeQAxjF8gle0_aA.png 1100w, https://miro.medium.com/v2/resize:fit:840/1*MXY5i10BeQAxjF8gle0_aA.png 840w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 420px"/>
                                                                        <img alt="" class="bg mv ob c" width="420" height="316" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">Sigmoid Plot  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="9e04" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">This function squeezes its input into a narrow range between 0 and 1. Its like taking any value, no matter how large or small, and translating it into a probability.</p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np rs">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*cih3qtKihKCbo48RwR6O2w.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*cih3qtKihKCbo48RwR6O2w.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*cih3qtKihKCbo48RwR6O2w.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*cih3qtKihKCbo48RwR6O2w.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*cih3qtKihKCbo48RwR6O2w.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*cih3qtKihKCbo48RwR6O2w.png 1100w, https://miro.medium.com/v2/resize:fit:476/format:webp/1*cih3qtKihKCbo48RwR6O2w.png 476w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 238px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*cih3qtKihKCbo48RwR6O2w.png 640w, https://miro.medium.com/v2/resize:fit:720/1*cih3qtKihKCbo48RwR6O2w.png 720w, https://miro.medium.com/v2/resize:fit:750/1*cih3qtKihKCbo48RwR6O2w.png 750w, https://miro.medium.com/v2/resize:fit:786/1*cih3qtKihKCbo48RwR6O2w.png 786w, https://miro.medium.com/v2/resize:fit:828/1*cih3qtKihKCbo48RwR6O2w.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*cih3qtKihKCbo48RwR6O2w.png 1100w, https://miro.medium.com/v2/resize:fit:476/1*cih3qtKihKCbo48RwR6O2w.png 476w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 238px"/>
                                                                        <img alt="" class="bg mv ob c" width="238" height="54" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">Sigmoid Function  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="4a70" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Youll see sigmoid functions in the final layer of binary classification networks, where you need to decide between two options  yes or no, true or false, 1 or 0.</p>
                                                            <p id="4ca1" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">Hyperbolic Tangent Function (tanh)</strong>
                                                            </p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np rt">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Pl8TMERMrWfHe2LrmvuHJw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Pl8TMERMrWfHe2LrmvuHJw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Pl8TMERMrWfHe2LrmvuHJw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Pl8TMERMrWfHe2LrmvuHJw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Pl8TMERMrWfHe2LrmvuHJw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Pl8TMERMrWfHe2LrmvuHJw.png 1100w, https://miro.medium.com/v2/resize:fit:862/format:webp/1*Pl8TMERMrWfHe2LrmvuHJw.png 862w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 431px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*Pl8TMERMrWfHe2LrmvuHJw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*Pl8TMERMrWfHe2LrmvuHJw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*Pl8TMERMrWfHe2LrmvuHJw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*Pl8TMERMrWfHe2LrmvuHJw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*Pl8TMERMrWfHe2LrmvuHJw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*Pl8TMERMrWfHe2LrmvuHJw.png 1100w, https://miro.medium.com/v2/resize:fit:862/1*Pl8TMERMrWfHe2LrmvuHJw.png 862w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 431px"/>
                                                                        <img alt="" class="bg mv ob c" width="431" height="316" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">tanh Plot  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="1fe0" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">tanh stretches the output range to between -1 and 1. This centers the data around 0, making it easier for layers down the line to learn from it.</p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np ru">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*ALm_9w6JMsOjUjhLnu6Eqw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*ALm_9w6JMsOjUjhLnu6Eqw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*ALm_9w6JMsOjUjhLnu6Eqw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*ALm_9w6JMsOjUjhLnu6Eqw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*ALm_9w6JMsOjUjhLnu6Eqw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ALm_9w6JMsOjUjhLnu6Eqw.png 1100w, https://miro.medium.com/v2/resize:fit:1040/format:webp/1*ALm_9w6JMsOjUjhLnu6Eqw.png 1040w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 520px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*ALm_9w6JMsOjUjhLnu6Eqw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*ALm_9w6JMsOjUjhLnu6Eqw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*ALm_9w6JMsOjUjhLnu6Eqw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*ALm_9w6JMsOjUjhLnu6Eqw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*ALm_9w6JMsOjUjhLnu6Eqw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*ALm_9w6JMsOjUjhLnu6Eqw.png 1100w, https://miro.medium.com/v2/resize:fit:1040/1*ALm_9w6JMsOjUjhLnu6Eqw.png 1040w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 520px"/>
                                                                        <img alt="" class="bg mv ob c" width="520" height="54" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">tanh formula  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="4545" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Its often found in the hidden layers, helping to model more complex data relationships by balancing the input signal.</p>
                                                            <p id="f025" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">Rectified Linear Unit (ReLU)</strong>
                                                            </p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np rv">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*-38maoM351zOYZvYx0Z5iQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*-38maoM351zOYZvYx0Z5iQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*-38maoM351zOYZvYx0Z5iQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*-38maoM351zOYZvYx0Z5iQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*-38maoM351zOYZvYx0Z5iQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*-38maoM351zOYZvYx0Z5iQ.png 1100w, https://miro.medium.com/v2/resize:fit:830/format:webp/1*-38maoM351zOYZvYx0Z5iQ.png 830w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 415px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*-38maoM351zOYZvYx0Z5iQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*-38maoM351zOYZvYx0Z5iQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*-38maoM351zOYZvYx0Z5iQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*-38maoM351zOYZvYx0Z5iQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*-38maoM351zOYZvYx0Z5iQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*-38maoM351zOYZvYx0Z5iQ.png 1100w, https://miro.medium.com/v2/resize:fit:830/1*-38maoM351zOYZvYx0Z5iQ.png 830w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 415px"/>
                                                                        <img alt="" class="bg mv ob c" width="415" height="316" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">ReLU Plot  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="dead" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">ReLU is like a gatekeeper that passes positive values unchanged but blocks negatives, turning them to zero. This simplicity makes it very efficient and helps overcome some tricky problems in training deep neural networks.</p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np rw">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*5iye9eVZvnQxCiu7zSLpzQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*5iye9eVZvnQxCiu7zSLpzQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*5iye9eVZvnQxCiu7zSLpzQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*5iye9eVZvnQxCiu7zSLpzQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*5iye9eVZvnQxCiu7zSLpzQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*5iye9eVZvnQxCiu7zSLpzQ.png 1100w, https://miro.medium.com/v2/resize:fit:604/format:webp/1*5iye9eVZvnQxCiu7zSLpzQ.png 604w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 302px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*5iye9eVZvnQxCiu7zSLpzQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*5iye9eVZvnQxCiu7zSLpzQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*5iye9eVZvnQxCiu7zSLpzQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*5iye9eVZvnQxCiu7zSLpzQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*5iye9eVZvnQxCiu7zSLpzQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*5iye9eVZvnQxCiu7zSLpzQ.png 1100w, https://miro.medium.com/v2/resize:fit:604/1*5iye9eVZvnQxCiu7zSLpzQ.png 604w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 302px"/>
                                                                        <img alt="" class="bg mv ob c" width="302" height="41" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">ReLU function  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="9c9f" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Its simplicity and efficiency have made ReLU incredibly popular, especially in convolutional neural networks (CNNs) and deep learning models.</p>
                                                            <p id="d4d8" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">Leaky Rectified Linear Unit (Leaky ReLU)</strong>
                                                            </p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np rv">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*2uxUYY0YRzzkzFZ9r73vMA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*2uxUYY0YRzzkzFZ9r73vMA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*2uxUYY0YRzzkzFZ9r73vMA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*2uxUYY0YRzzkzFZ9r73vMA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*2uxUYY0YRzzkzFZ9r73vMA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*2uxUYY0YRzzkzFZ9r73vMA.png 1100w, https://miro.medium.com/v2/resize:fit:830/format:webp/1*2uxUYY0YRzzkzFZ9r73vMA.png 830w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 415px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*2uxUYY0YRzzkzFZ9r73vMA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*2uxUYY0YRzzkzFZ9r73vMA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*2uxUYY0YRzzkzFZ9r73vMA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*2uxUYY0YRzzkzFZ9r73vMA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*2uxUYY0YRzzkzFZ9r73vMA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*2uxUYY0YRzzkzFZ9r73vMA.png 1100w, https://miro.medium.com/v2/resize:fit:830/1*2uxUYY0YRzzkzFZ9r73vMA.png 830w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 415px"/>
                                                                        <img alt="" class="bg mv ob c" width="415" height="316" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">Leaky ReLU Plot  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="af4d" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Leaky ReLU allows a tiny, non-zero gradient when the input is less than zero, which keeps neurons alive and kicking even when theyre not actively firing.</p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np rx">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Oaytq6hBJ5_9nTvMJqhQIw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Oaytq6hBJ5_9nTvMJqhQIw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Oaytq6hBJ5_9nTvMJqhQIw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Oaytq6hBJ5_9nTvMJqhQIw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Oaytq6hBJ5_9nTvMJqhQIw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Oaytq6hBJ5_9nTvMJqhQIw.png 1100w, https://miro.medium.com/v2/resize:fit:664/format:webp/1*Oaytq6hBJ5_9nTvMJqhQIw.png 664w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 332px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*Oaytq6hBJ5_9nTvMJqhQIw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*Oaytq6hBJ5_9nTvMJqhQIw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*Oaytq6hBJ5_9nTvMJqhQIw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*Oaytq6hBJ5_9nTvMJqhQIw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*Oaytq6hBJ5_9nTvMJqhQIw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*Oaytq6hBJ5_9nTvMJqhQIw.png 1100w, https://miro.medium.com/v2/resize:fit:664/1*Oaytq6hBJ5_9nTvMJqhQIw.png 664w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 332px"/>
                                                                        <img alt="" class="bg mv ob c" width="332" height="41" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">Leaky ReLU  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="f56e" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Its a tweak to ReLU used in cases where the network might suffer from dead neurons, ensuring all parts of the network stay active over time.</p>
                                                            <p id="ac01" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">Exponential Linear Unit (ELU)</strong>
                                                            </p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np rv">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*7VfpmvsNSJMikpglmZL_gg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*7VfpmvsNSJMikpglmZL_gg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*7VfpmvsNSJMikpglmZL_gg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*7VfpmvsNSJMikpglmZL_gg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*7VfpmvsNSJMikpglmZL_gg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*7VfpmvsNSJMikpglmZL_gg.png 1100w, https://miro.medium.com/v2/resize:fit:830/format:webp/1*7VfpmvsNSJMikpglmZL_gg.png 830w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 415px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*7VfpmvsNSJMikpglmZL_gg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*7VfpmvsNSJMikpglmZL_gg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*7VfpmvsNSJMikpglmZL_gg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*7VfpmvsNSJMikpglmZL_gg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*7VfpmvsNSJMikpglmZL_gg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*7VfpmvsNSJMikpglmZL_gg.png 1100w, https://miro.medium.com/v2/resize:fit:830/1*7VfpmvsNSJMikpglmZL_gg.png 830w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 415px"/>
                                                                        <img alt="" class="bg mv ob c" width="415" height="316" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">ELU Plot  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="9e20" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                ELU smooths out the function for negative inputs (using a parameter <em class="rl"></em>
                                                                for scaling), allowing for negative outputs but with a gentle curve. This can help the network maintain a mean activation closer to zero, improving learning dynamics.
                                                            </p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np ry">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*RcQvabbkO9_djicqEh-rtA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*RcQvabbkO9_djicqEh-rtA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*RcQvabbkO9_djicqEh-rtA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*RcQvabbkO9_djicqEh-rtA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*RcQvabbkO9_djicqEh-rtA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*RcQvabbkO9_djicqEh-rtA.png 1100w, https://miro.medium.com/v2/resize:fit:1098/format:webp/1*RcQvabbkO9_djicqEh-rtA.png 1098w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 549px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*RcQvabbkO9_djicqEh-rtA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*RcQvabbkO9_djicqEh-rtA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*RcQvabbkO9_djicqEh-rtA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*RcQvabbkO9_djicqEh-rtA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*RcQvabbkO9_djicqEh-rtA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*RcQvabbkO9_djicqEh-rtA.png 1100w, https://miro.medium.com/v2/resize:fit:1098/1*RcQvabbkO9_djicqEh-rtA.png 1098w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 549px"/>
                                                                        <img alt="" class="bg mv ob c" width="549" height="125" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">ELU Function  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="f123" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Useful in deeper networks where ReLUs sharp threshold could slow down learning.</p>
                                                            <p id="b063" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">Softmax Function</strong>
                                                            </p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np rr">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*w5fS4rm-d2q2fvXdTE6jcA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*w5fS4rm-d2q2fvXdTE6jcA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*w5fS4rm-d2q2fvXdTE6jcA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*w5fS4rm-d2q2fvXdTE6jcA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*w5fS4rm-d2q2fvXdTE6jcA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*w5fS4rm-d2q2fvXdTE6jcA.png 1100w, https://miro.medium.com/v2/resize:fit:840/format:webp/1*w5fS4rm-d2q2fvXdTE6jcA.png 840w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 420px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*w5fS4rm-d2q2fvXdTE6jcA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*w5fS4rm-d2q2fvXdTE6jcA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*w5fS4rm-d2q2fvXdTE6jcA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*w5fS4rm-d2q2fvXdTE6jcA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*w5fS4rm-d2q2fvXdTE6jcA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*w5fS4rm-d2q2fvXdTE6jcA.png 1100w, https://miro.medium.com/v2/resize:fit:840/1*w5fS4rm-d2q2fvXdTE6jcA.png 840w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 420px"/>
                                                                        <img alt="" class="bg mv ob c" width="420" height="316" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">Softmax Function  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="3022" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">The softmax function turns logits, the raw output scores from the neurons, into probabilities by exponentiating and normalizing them. It ensures that the output values sum up to one, making them directly interpretable as probabilities.</p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np rz">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*yTARm0UZeVlowjRw8gN0QA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*yTARm0UZeVlowjRw8gN0QA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*yTARm0UZeVlowjRw8gN0QA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*yTARm0UZeVlowjRw8gN0QA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*yTARm0UZeVlowjRw8gN0QA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*yTARm0UZeVlowjRw8gN0QA.png 1100w, https://miro.medium.com/v2/resize:fit:518/format:webp/1*yTARm0UZeVlowjRw8gN0QA.png 518w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 259px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*yTARm0UZeVlowjRw8gN0QA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*yTARm0UZeVlowjRw8gN0QA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*yTARm0UZeVlowjRw8gN0QA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*yTARm0UZeVlowjRw8gN0QA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*yTARm0UZeVlowjRw8gN0QA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*yTARm0UZeVlowjRw8gN0QA.png 1100w, https://miro.medium.com/v2/resize:fit:518/1*yTARm0UZeVlowjRw8gN0QA.png 518w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 259px"/>
                                                                        <img alt="" class="bg mv ob c" width="259" height="66" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">Softmax Function  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="ff13" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Its the go-to for the output layer in multi-class classification problems, where each neuron corresponds to a different class, and you want to pick the most likely one.</p>
                                                            <h2 id="03fd" class="qh pm gu be pn qi qj dx pq qk ql dz pt op qm qn qo ot qp qq qr ox qs qt qu qv bj">3.3: Backpropagation: The Core of Neural Learning</h2>
                                                            <p id="ed04" class="pw-post-body-paragraph og oh gu oi b hs qw ok ol hv qx on oo op qy or os ot qz ov ow ox ra oz pa pb gn bj">Backpropagation, short for backward propagation of errors, is a method for efficiently calculating the gradient of the loss function concerning all weights in the network. It consists of two main phases: a forward pass, where the input data is passed through the network to generate an output, and a backward pass, where the output is compared to the target value, and the error is propagated back through the network to update the weights.</p>
                                                            <p id="17b9" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">The essence of backpropagation is the chain rule of calculus, which is used to calculate the gradients of the loss function for each weight by multiplying the gradients of the layers behind it. This process reveals how much each weight contributes to the error, providing a clear path for its adjustment.</p>
                                                            <p id="9e0c" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">The chain rule for backpropagation can be represented as follows:</p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np sa">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*wMHhFGdHU7Sbbc4uFdbL2g.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*wMHhFGdHU7Sbbc4uFdbL2g.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*wMHhFGdHU7Sbbc4uFdbL2g.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*wMHhFGdHU7Sbbc4uFdbL2g.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*wMHhFGdHU7Sbbc4uFdbL2g.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*wMHhFGdHU7Sbbc4uFdbL2g.png 1100w, https://miro.medium.com/v2/resize:fit:628/format:webp/1*wMHhFGdHU7Sbbc4uFdbL2g.png 628w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 314px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*wMHhFGdHU7Sbbc4uFdbL2g.png 640w, https://miro.medium.com/v2/resize:fit:720/1*wMHhFGdHU7Sbbc4uFdbL2g.png 720w, https://miro.medium.com/v2/resize:fit:750/1*wMHhFGdHU7Sbbc4uFdbL2g.png 750w, https://miro.medium.com/v2/resize:fit:786/1*wMHhFGdHU7Sbbc4uFdbL2g.png 786w, https://miro.medium.com/v2/resize:fit:828/1*wMHhFGdHU7Sbbc4uFdbL2g.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*wMHhFGdHU7Sbbc4uFdbL2g.png 1100w, https://miro.medium.com/v2/resize:fit:628/1*wMHhFGdHU7Sbbc4uFdbL2g.png 628w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 314px"/>
                                                                        <img alt="" class="bg mv ob c" width="314" height="52" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">Chain of Rule in backpropagation  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="00c7" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">where:</p>
                                                            <ul class="">
                                                                <li id="87cf" class="og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb ri rj rk bj">
                                                                    <strong class="oi gv">
                                                                        <em class="rl">a/</em>
                                                                        <em class="rl">L</em>
                                                                    </strong>
                                                                     is the gradient of the loss function to the activation,
                                                                </li>
                                                                <li id="4efa" class="og oh gu oi b hs rm ok ol hv rn on oo op ro or os ot rp ov ow ox rq oz pa pb ri rj rk bj">
                                                                    <strong class="oi gv">
                                                                        <em class="rl">z/</em>
                                                                        <em class="rl">a</em>
                                                                        
                                                                    </strong>
                                                                    is the gradient of the activation function to the weighted input <em class="rl">z</em>
                                                                    ,
                                                                </li>
                                                                <li id="2cff" class="og oh gu oi b hs rm ok ol hv rn on oo op ro or os ot rp ov ow ox rq oz pa pb ri rj rk bj">
                                                                    <strong class="oi gv">
                                                                        <em class="rl">w/</em>
                                                                        <em class="rl">z</em>
                                                                        
                                                                    </strong>
                                                                    is the gradient of the weighted input to the weight <em class="rl">w</em>
                                                                    ,
                                                                </li>
                                                                <li id="8c17" class="og oh gu oi b hs rm ok ol hv rn on oo op ro or os ot rp ov ow ox rq oz pa pb ri rj rk bj">
                                                                    <strong class="oi gv">
                                                                        <em class="rl">z</em>
                                                                    </strong>
                                                                    represents the weighted sum of inputs and <em class="rl">a</em>
                                                                    is the activation.
                                                                </li>
                                                            </ul>
                                                            <p id="81ca" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">
                                                                    Gradient Descent: Optimizing the Weights<br/>
                                                                </strong>
                                                                Gradient Descent is an optimization algorithm used for minimizing the loss function in a neural network. It works by iteratively moving the weights in the direction of the steepest decrease in loss. The amount by which the weights are adjusted in each iteration is determined by the learning rate, a hyperparameter that controls the size of the steps.
                                                            </p>
                                                            <p id="8097" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Mathematically, the weight update rule in gradient descent can be expressed as:</p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np sb">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*a17xUzndthmCUadaJ3AtHg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*a17xUzndthmCUadaJ3AtHg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*a17xUzndthmCUadaJ3AtHg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*a17xUzndthmCUadaJ3AtHg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*a17xUzndthmCUadaJ3AtHg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*a17xUzndthmCUadaJ3AtHg.png 1100w, https://miro.medium.com/v2/resize:fit:744/format:webp/1*a17xUzndthmCUadaJ3AtHg.png 744w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 372px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*a17xUzndthmCUadaJ3AtHg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*a17xUzndthmCUadaJ3AtHg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*a17xUzndthmCUadaJ3AtHg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*a17xUzndthmCUadaJ3AtHg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*a17xUzndthmCUadaJ3AtHg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*a17xUzndthmCUadaJ3AtHg.png 1100w, https://miro.medium.com/v2/resize:fit:744/1*a17xUzndthmCUadaJ3AtHg.png 744w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 372px"/>
                                                                        <img alt="" class="bg mv ob c" width="372" height="52" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">Gradient Descent Formula  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="d651" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">where:</p>
                                                            <ul class="">
                                                                <li id="2eab" class="og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb ri rj rk bj">
                                                                    <strong class="oi gv">
                                                                        <em class="rl">w-</em>
                                                                        new
                                                                    </strong>
                                                                     and 
                                                                    <strong class="oi gv">
                                                                        <em class="rl">w-</em>
                                                                        old
                                                                    </strong>
                                                                     represent the updated (new) and current (old) values of the weight, respectively,
                                                                </li>
                                                                <li id="2abd" class="og oh gu oi b hs rm ok ol hv rn on oo op ro or os ot rp ov ow ox rq oz pa pb ri rj rk bj">
                                                                    <strong class="oi gv"></strong>
                                                                    is the learning rate, a hyperparameter that controls the size of the step taken in the direction of the negative gradient,
                                                                </li>
                                                                <li id="e5d6" class="og oh gu oi b hs rm ok ol hv rn on oo op ro or os ot rp ov ow ox rq oz pa pb ri rj rk bj">
                                                                    <strong class="oi gv">
                                                                        <em class="rl">w/</em>
                                                                        <em class="rl">L</em>
                                                                    </strong>
                                                                     is the gradient of the loss function for the weight.
                                                                </li>
                                                            </ul>
                                                            <p id="1df5" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">In practice, backpropagation and gradient descent are performed in tandem. Backpropagation computes the gradient (the direction and magnitude of the error) for each weight in the network, and gradient descent uses this information to update the weights to minimize the loss. This iterative process continues until the model converges to a state where the loss is minimized or a criterion is met.</p>
                                                            <h2 id="d519" class="qh pm gu be pn qi qj dx pq qk ql dz pt op qm qn qo ot qp qq qr ox qs qt qu qv bj">3.4: Step by Step example</h2>
                                                            <p id="5143" class="pw-post-body-paragraph og oh gu oi b hs qw ok ol hv qx on oo op qy or os ot qz ov ow ox ra oz pa pb gn bj">Lets explore an example involving backpropagation and gradient descent in a simple neural network. This neural network will have a single hidden layer. Well work through a single iteration of training with one data point to understand how these processes update the networks weights.</p>
                                                            <p id="e0b8" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">Network Structure:</strong>
                                                            </p>
                                                            <ul class="">
                                                                <li id="b2c1" class="og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb ri rj rk bj">
                                                                    <strong class="oi gv">Inputs</strong>
                                                                    : <em class="rl">x</em>
                                                                    1, <em class="rl">x</em>
                                                                    2 (2-dimensional input vector)
                                                                </li>
                                                                <li id="afe4" class="og oh gu oi b hs rm ok ol hv rn on oo op ro or os ot rp ov ow ox rq oz pa pb ri rj rk bj">
                                                                    <strong class="oi gv">Hidden Layer</strong>
                                                                    : 2 neurons, with activation function <em class="rl">f</em>
                                                                    (<em class="rl">z</em>
                                                                    )=ReLU(<em class="rl">z</em>
                                                                    )=max(0,<em class="rl">z</em>
                                                                    )
                                                                </li>
                                                                <li id="1387" class="og oh gu oi b hs rm ok ol hv rn on oo op ro or os ot rp ov ow ox rq oz pa pb ri rj rk bj">
                                                                    <strong class="oi gv">Output Layer</strong>
                                                                    : 1 neuron, with activation function <em class="rl">g</em>
                                                                    (<em class="rl">z</em>
                                                                    )=<em class="rl"></em>
                                                                    (<em class="rl">z</em>
                                                                    )=1+<em class="rl">e</em>
                                                                    <em class="rl">z</em>
                                                                    1 (Sigmoid function for binary classification)
                                                                </li>
                                                                <li id="2a05" class="og oh gu oi b hs rm ok ol hv rn on oo op ro or os ot rp ov ow ox rq oz pa pb ri rj rk bj">
                                                                    <strong class="oi gv">Loss Function</strong>
                                                                    : Binary Cross-Entropy Loss.
                                                                </li>
                                                            </ul>
                                                            <p id="e62b" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">
                                                                    Forward Pass<br/>
                                                                </strong>
                                                                Given inputs <em class="rl">x</em>
                                                                1, <em class="rl">x</em>
                                                                2, weights <em class="rl">w</em>
                                                                , and biases <em class="rl">b</em>
                                                                , the forward pass calculates the networks output. The process for a single hidden layer network with ReLU activation in the hidden layer and a sigmoid activation in the output layer is as follows:
                                                            </p>
                                                            <p id="afa8" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">
                                                                    1: Input to Hidden Layer<br/>
                                                                </strong>
                                                                Let the initial weights from the input to the hidden layer be <em class="rl">w</em>
                                                                11, <em class="rl">w</em>
                                                                12, <em class="rl">w</em>
                                                                21, <em class="rl">w</em>
                                                                22, and the biases be <em class="rl">b</em>
                                                                1, <em class="rl">b</em>
                                                                2 for the two hidden neurons, respectively.
                                                            </p>
                                                            <p id="402b" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                Given an input vector [<em class="rl">x</em>
                                                                1, <em class="rl">x</em>
                                                                2], the weighted sum for each neuron in the hidden layer is:
                                                            </p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np sc">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*s6ErDwvlFxo4MLc418jIkw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*s6ErDwvlFxo4MLc418jIkw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*s6ErDwvlFxo4MLc418jIkw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*s6ErDwvlFxo4MLc418jIkw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*s6ErDwvlFxo4MLc418jIkw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*s6ErDwvlFxo4MLc418jIkw.png 1100w, https://miro.medium.com/v2/resize:fit:882/format:webp/1*s6ErDwvlFxo4MLc418jIkw.png 882w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 441px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*s6ErDwvlFxo4MLc418jIkw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*s6ErDwvlFxo4MLc418jIkw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*s6ErDwvlFxo4MLc418jIkw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*s6ErDwvlFxo4MLc418jIkw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*s6ErDwvlFxo4MLc418jIkw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*s6ErDwvlFxo4MLc418jIkw.png 1100w, https://miro.medium.com/v2/resize:fit:882/1*s6ErDwvlFxo4MLc418jIkw.png 882w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 441px"/>
                                                                        <img alt="" class="bg mv ob c" width="441" height="84" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">Hidden Layer Weighted Sum  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="1b26" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Applying the ReLU activation function:</p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np sd">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*yA0I4q_KuoAJUJ9NX5K07w.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*yA0I4q_KuoAJUJ9NX5K07w.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*yA0I4q_KuoAJUJ9NX5K07w.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*yA0I4q_KuoAJUJ9NX5K07w.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*yA0I4q_KuoAJUJ9NX5K07w.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*yA0I4q_KuoAJUJ9NX5K07w.png 1100w, https://miro.medium.com/v2/resize:fit:1018/format:webp/1*yA0I4q_KuoAJUJ9NX5K07w.png 1018w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 509px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*yA0I4q_KuoAJUJ9NX5K07w.png 640w, https://miro.medium.com/v2/resize:fit:720/1*yA0I4q_KuoAJUJ9NX5K07w.png 720w, https://miro.medium.com/v2/resize:fit:750/1*yA0I4q_KuoAJUJ9NX5K07w.png 750w, https://miro.medium.com/v2/resize:fit:786/1*yA0I4q_KuoAJUJ9NX5K07w.png 786w, https://miro.medium.com/v2/resize:fit:828/1*yA0I4q_KuoAJUJ9NX5K07w.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*yA0I4q_KuoAJUJ9NX5K07w.png 1100w, https://miro.medium.com/v2/resize:fit:1018/1*yA0I4q_KuoAJUJ9NX5K07w.png 1018w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 509px"/>
                                                                        <img alt="" class="bg mv ob c" width="509" height="91" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">Hidden Layer ReLU Activation  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="24c0" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">1.2: Hidden Layer to Output:</strong>
                                                            </p>
                                                            <p id="a18d" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                Let the weights from the hidden layer to the output neuron be <em class="rl">w</em>
                                                                31, <em class="rl">w</em>
                                                                32, and the bias be <em class="rl">b</em>
                                                                3.
                                                            </p>
                                                            <p id="6021" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">The weighted sum at the output neuron is:</p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np se">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*j2wud-bHmSyb-V-LcGhxNg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*j2wud-bHmSyb-V-LcGhxNg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*j2wud-bHmSyb-V-LcGhxNg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*j2wud-bHmSyb-V-LcGhxNg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*j2wud-bHmSyb-V-LcGhxNg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*j2wud-bHmSyb-V-LcGhxNg.png 1100w, https://miro.medium.com/v2/resize:fit:874/format:webp/1*j2wud-bHmSyb-V-LcGhxNg.png 874w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 437px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*j2wud-bHmSyb-V-LcGhxNg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*j2wud-bHmSyb-V-LcGhxNg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*j2wud-bHmSyb-V-LcGhxNg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*j2wud-bHmSyb-V-LcGhxNg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*j2wud-bHmSyb-V-LcGhxNg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*j2wud-bHmSyb-V-LcGhxNg.png 1100w, https://miro.medium.com/v2/resize:fit:874/1*j2wud-bHmSyb-V-LcGhxNg.png 874w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 437px"/>
                                                                        <img alt="" class="bg mv ob c" width="437" height="35" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">Output Layer Weighted Sum  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="2b81" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Applying the Sigmoid activation function for the output:</p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np sf">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*BP4Baewz9XQyOmvStglIIQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*BP4Baewz9XQyOmvStglIIQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*BP4Baewz9XQyOmvStglIIQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*BP4Baewz9XQyOmvStglIIQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*BP4Baewz9XQyOmvStglIIQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*BP4Baewz9XQyOmvStglIIQ.png 1100w, https://miro.medium.com/v2/resize:fit:690/format:webp/1*BP4Baewz9XQyOmvStglIIQ.png 690w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 345px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*BP4Baewz9XQyOmvStglIIQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*BP4Baewz9XQyOmvStglIIQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*BP4Baewz9XQyOmvStglIIQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*BP4Baewz9XQyOmvStglIIQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*BP4Baewz9XQyOmvStglIIQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*BP4Baewz9XQyOmvStglIIQ.png 1100w, https://miro.medium.com/v2/resize:fit:690/1*BP4Baewz9XQyOmvStglIIQ.png 690w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 345px"/>
                                                                        <img alt="" class="bg mv ob c" width="345" height="55" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">Output Layer Sigmoid Activation  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="5f30" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Loss Calculation (Binary Cross-Entropy):</p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np sg">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*zfB-SQ73Ra-AMyAmV7ZhFg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*zfB-SQ73Ra-AMyAmV7ZhFg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*zfB-SQ73Ra-AMyAmV7ZhFg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*zfB-SQ73Ra-AMyAmV7ZhFg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*zfB-SQ73Ra-AMyAmV7ZhFg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*zfB-SQ73Ra-AMyAmV7ZhFg.png 1100w, https://miro.medium.com/v2/resize:fit:1284/format:webp/1*zfB-SQ73Ra-AMyAmV7ZhFg.png 1284w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 642px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*zfB-SQ73Ra-AMyAmV7ZhFg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*zfB-SQ73Ra-AMyAmV7ZhFg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*zfB-SQ73Ra-AMyAmV7ZhFg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*zfB-SQ73Ra-AMyAmV7ZhFg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*zfB-SQ73Ra-AMyAmV7ZhFg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*zfB-SQ73Ra-AMyAmV7ZhFg.png 1100w, https://miro.medium.com/v2/resize:fit:1284/1*zfB-SQ73Ra-AMyAmV7ZhFg.png 1284w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 642px"/>
                                                                        <img alt="" class="bg mv ob c" width="642" height="41" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">Cross-Entropy Formula  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="33f3" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">
                                                                    Backward Pass (Backpropagation):<br/>
                                                                </strong>
                                                                Now things get a bit more complex, as we need to calculate the gradient on the formulas we applied in the forward pass.
                                                            </p>
                                                            <p id="cf16" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">
                                                                    Output Layer Gradients<br/>
                                                                </strong>
                                                                Lets start with the output layer. The derivative of the loss function for <em class="rl">z</em>
                                                                3 is:
                                                            </p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div role="button" tabindex="0" class="nx ny fi nz bg oa">
                                                                    <div class="no np sh">
                                                                        <picture>
                                                                            <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*yhNTwdJMP7ioXgypWPphag.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*yhNTwdJMP7ioXgypWPphag.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*yhNTwdJMP7ioXgypWPphag.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*yhNTwdJMP7ioXgypWPphag.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*yhNTwdJMP7ioXgypWPphag.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*yhNTwdJMP7ioXgypWPphag.png 1100w, https://miro.medium.com/v2/resize:fit:410/format:webp/1*yhNTwdJMP7ioXgypWPphag.png 410w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 205px" type="image/webp"/>
                                                                            <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*yhNTwdJMP7ioXgypWPphag.png 640w, https://miro.medium.com/v2/resize:fit:720/1*yhNTwdJMP7ioXgypWPphag.png 720w, https://miro.medium.com/v2/resize:fit:750/1*yhNTwdJMP7ioXgypWPphag.png 750w, https://miro.medium.com/v2/resize:fit:786/1*yhNTwdJMP7ioXgypWPphag.png 786w, https://miro.medium.com/v2/resize:fit:828/1*yhNTwdJMP7ioXgypWPphag.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*yhNTwdJMP7ioXgypWPphag.png 1100w, https://miro.medium.com/v2/resize:fit:410/1*yhNTwdJMP7ioXgypWPphag.png 410w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 205px"/>
                                                                            <img alt="" class="bg mv ob c" width="205" height="57" loading="lazy" role="presentation"/>
                                                                        </picture>
                                                                    </div>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">Output Layer Activation Gradient  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="d1d2" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">The gradients of the loss for weights and bias of the output layer:</p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np si">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*8RxFYpMFabjACbJeADxq6Q.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*8RxFYpMFabjACbJeADxq6Q.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*8RxFYpMFabjACbJeADxq6Q.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*8RxFYpMFabjACbJeADxq6Q.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*8RxFYpMFabjACbJeADxq6Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*8RxFYpMFabjACbJeADxq6Q.png 1100w, https://miro.medium.com/v2/resize:fit:526/format:webp/1*8RxFYpMFabjACbJeADxq6Q.png 526w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 263px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*8RxFYpMFabjACbJeADxq6Q.png 640w, https://miro.medium.com/v2/resize:fit:720/1*8RxFYpMFabjACbJeADxq6Q.png 720w, https://miro.medium.com/v2/resize:fit:750/1*8RxFYpMFabjACbJeADxq6Q.png 750w, https://miro.medium.com/v2/resize:fit:786/1*8RxFYpMFabjACbJeADxq6Q.png 786w, https://miro.medium.com/v2/resize:fit:828/1*8RxFYpMFabjACbJeADxq6Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*8RxFYpMFabjACbJeADxq6Q.png 1100w, https://miro.medium.com/v2/resize:fit:526/1*8RxFYpMFabjACbJeADxq6Q.png 526w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 263px"/>
                                                                        <img alt="" class="bg mv ob c" width="263" height="255" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">Output Layer Gradient  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="f8f3" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">
                                                                    Hidden Layer Gradients<br/>
                                                                </strong>
                                                                The gradients of the loss for the hidden layer activations (chain rule applied):
                                                            </p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np sj">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*0nbCbiuCI9lhoojtekd72A.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*0nbCbiuCI9lhoojtekd72A.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*0nbCbiuCI9lhoojtekd72A.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*0nbCbiuCI9lhoojtekd72A.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*0nbCbiuCI9lhoojtekd72A.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*0nbCbiuCI9lhoojtekd72A.png 1100w, https://miro.medium.com/v2/resize:fit:536/format:webp/1*0nbCbiuCI9lhoojtekd72A.png 536w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 268px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*0nbCbiuCI9lhoojtekd72A.png 640w, https://miro.medium.com/v2/resize:fit:720/1*0nbCbiuCI9lhoojtekd72A.png 720w, https://miro.medium.com/v2/resize:fit:750/1*0nbCbiuCI9lhoojtekd72A.png 750w, https://miro.medium.com/v2/resize:fit:786/1*0nbCbiuCI9lhoojtekd72A.png 786w, https://miro.medium.com/v2/resize:fit:828/1*0nbCbiuCI9lhoojtekd72A.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*0nbCbiuCI9lhoojtekd72A.png 1100w, https://miro.medium.com/v2/resize:fit:536/1*0nbCbiuCI9lhoojtekd72A.png 536w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 268px"/>
                                                                        <img alt="" class="bg mv ob c" width="268" height="155" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">Hidden Layer Activation Gradient  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="da12" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">The gradients of the loss concerning weights and biases of the hidden layer:</p>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div class="no np sk">
                                                                    <picture>
                                                                        <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*EVXulwpZjCyeZkq8U-zXTg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*EVXulwpZjCyeZkq8U-zXTg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*EVXulwpZjCyeZkq8U-zXTg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*EVXulwpZjCyeZkq8U-zXTg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*EVXulwpZjCyeZkq8U-zXTg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*EVXulwpZjCyeZkq8U-zXTg.png 1100w, https://miro.medium.com/v2/resize:fit:722/format:webp/1*EVXulwpZjCyeZkq8U-zXTg.png 722w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 361px" type="image/webp"/>
                                                                        <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*EVXulwpZjCyeZkq8U-zXTg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*EVXulwpZjCyeZkq8U-zXTg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*EVXulwpZjCyeZkq8U-zXTg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*EVXulwpZjCyeZkq8U-zXTg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*EVXulwpZjCyeZkq8U-zXTg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*EVXulwpZjCyeZkq8U-zXTg.png 1100w, https://miro.medium.com/v2/resize:fit:722/1*EVXulwpZjCyeZkq8U-zXTg.png 722w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 361px"/>
                                                                        <img alt="" class="bg mv ob c" width="361" height="555" loading="lazy" role="presentation"/>
                                                                    </picture>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">Hidden Layer Gradient  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="9f1e" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">These steps are then repeated until a criterion is met, such as a maximum number of epochs.</p>
                                                            <h2 id="e495" class="qh pm gu be pn qi qj dx pq qk ql dz pt op qm qn qo ot qp qq qr ox qs qt qu qv bj">3.5: Improvements</h2>
                                                            <p id="4a87" class="pw-post-body-paragraph og oh gu oi b hs qw ok ol hv qx on oo op qy or os ot qz ov ow ox ra oz pa pb gn bj">While the basic idea of Gradient Descent is simple  take small steps in the direction that reduces error the most  several tweaks and improvements have been made to this method to enhance its efficiency and effectiveness.</p>
                                                            <p id="fda7" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">Stochastic Gradient Descent (SGD)</strong>
                                                                <br/>Stochastic Gradient Descent (SGD) takes the core idea of gradient descent but changes the approach by using just one training example at a time to calculate the gradient and update the weights. This method is similar to making decisions based on quick, individual observations rather than waiting to gather everyones opinion. It can make the learning process much faster because the model updates more frequently and with less computational burden.
                                                            </p>
                                                            <p id="02f5" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">To learn more about SGD look at this article:</p>
                                                            <div class="sl sm sn so sp sq">
                                                                <a rel="noopener follow" target="_blank" href="/stochastic-gradient-descent-math-and-python-code-35b5e66d6f79?source=post_page-----a34a51b93873--------------------------------">
                                                                    <div class="sr ab jo">
                                                                        <div class="ss ab cn ca st su">
                                                                            <h2 class="be gv jf z jw sv jy jz sw kb kd gt bj">Stochastic Gradient Descent: Math and Python Code</h2>
                                                                            <div class="sx l">
                                                                                <h3 class="be b jf z jw sv jy jz sw kb kd dt">Deep Dive on Stochastic Gradient Descent. Algorithm, assumptions, benefits, formula, and practical implementation.</h3>
                                                                            </div>
                                                                            <div class="sy l">
                                                                                <p class="be b du z jw sv jy jz sw kb kd dt">towardsdatascience.com</p>
                                                                            </div>
                                                                        </div>
                                                                        <div class="sz l">
                                                                            <div class="ta l tb tc td sz te mv sq"></div>
                                                                        </div>
                                                                    </div>
                                                                </a>
                                                            </div>
                                                            <p id="97c4" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">Adam (Adaptive Moment Estimation)</strong>
                                                                <br/>Adam, short for Adaptive Moment Estimation, is like the wise advisor to SGDs youthful energy. It takes the concept of adjusting weights based on the datas gradient but does so with a more sophisticated, personalized approach for each parameter in the model. Adam combines ideas from two other gradient descent improvements, AdaGrad and RMSProp, to adapt the learning rate for each weight in the network based on the first (mean) and second (uncentered variance) moments of the gradients.
                                                            </p>
                                                            <p id="8b8e" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Learn more about Adam Optimizer here:</p>
                                                            <div class="sl sm sn so sp sq">
                                                                <a rel="noopener follow" target="_blank" href="/the-math-behind-adam-optimizer-c41407efe59b?source=post_page-----a34a51b93873--------------------------------">
                                                                    <div class="sr ab jo">
                                                                        <div class="ss ab cn ca st su">
                                                                            <h2 class="be gv jf z jw sv jy jz sw kb kd gt bj">The Math behind Adam Optimizer</h2>
                                                                            <div class="sx l">
                                                                                <h3 class="be b jf z jw sv jy jz sw kb kd dt">Why is Adam the most popular optimizer in Deep Learning? Lets understand it by diving into its math, and recreating</h3>
                                                                            </div>
                                                                            <div class="sy l">
                                                                                <p class="be b du z jw sv jy jz sw kb kd dt">towardsdatascience.com</p>
                                                                            </div>
                                                                        </div>
                                                                        <div class="sz l">
                                                                            <div class="tf l tb tc td sz te mv sq"></div>
                                                                        </div>
                                                                    </div>
                                                                </a>
                                                            </div>
                                                            <h1 id="cd9e" class="pl pm gu be pn po rb hu pq pr rc hx pt pu rd pw px py re qa qb qc rf qe qf qg bj">4: Implementing Neural Networks</h1>
                                                            <h2 id="7f0a" class="qh pm gu be pn qi qj dx pq qk ql dz pt op qm qn qo ot qp qq qr ox qs qt qu qv bj">4.1: Building a Simple Neural Network in Python</h2>
                                                            <p id="1690" class="pw-post-body-paragraph og oh gu oi b hs qw ok ol hv qx on oo op qy or os ot qz ov ow ox ra oz pa pb gn bj">Lets finally recreate a neural network from scratch. For better readability, I will divide the code into 4 parts: NeuralNetwork class, Trainer class, and implementation.</p>
                                                            <p id="a7c2" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">You can find the whole code on this Jupyter Notebook. The notebook contains a fine-tuning bonus that will likely increase the performance of the Neural Network:</p>
                                                            <div class="sl sm sn so sp sq">
                                                                <a href="https://github.com/cristianleoo/models-from-scratch-python/blob/main/Neural%20Network/demo.ipynb?source=post_page-----a34a51b93873--------------------------------" rel="noopener  ugc nofollow" target="_blank">
                                                                    <div class="sr ab jo">
                                                                        <div class="ss ab cn ca st su">
                                                                            <h2 class="be gv jf z jw sv jy jz sw kb kd gt bj">models-from-scratch-python/Neural Network/demo.ipynb at main </h2>
                                                                            <div class="sx l">
                                                                                <h3 class="be b jf z jw sv jy jz sw kb kd dt">Repo where I recreate some popular machine learning models from scratch in Python - models-from-scratch-python/Neural</h3>
                                                                            </div>
                                                                            <div class="sy l">
                                                                                <p class="be b du z jw sv jy jz sw kb kd dt">github.com</p>
                                                                            </div>
                                                                        </div>
                                                                        <div class="sz l">
                                                                            <div class="tg l tb tc td sz te mv sq"></div>
                                                                        </div>
                                                                    </div>
                                                                </a>
                                                            </div>
                                                            <p id="e590" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">
                                                                    NeuralNetwork Class<br/>
                                                                </strong>
                                                                Lets start with the NN class, which defines the architecture of our Neural Network:
                                                            </p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="24b6" class="tl pm gu ti b bf tm tn l to tp">
                                                                    import numpy as np<br/>
                                                                    <br/>
                                                                    class NeuralNetwork:<br/>
                                                                    &quot;&quot;&quot;<br/>
                                                                    A simple neural network with one hidden layer.<br/>
                                                                    <br/>
                                                                    Parameters:<br/>
                                                                    -----------<br/>
                                                                    input_size: int<br/>
                                                                    The number of input features<br/>
                                                                    hidden_size: int<br/>
                                                                    The number of neurons in the hidden layer<br/>
                                                                    output_size: int<br/>
                                                                    The number of neurons in the output layer<br/>
                                                                    loss_func: str<br/>
                                                                    The loss function to use. Options are &#x27;mse &#x27;for mean squared error, &#x27;log_loss &#x27;for logistic loss, and &#x27;categorical_crossentropy &#x27;for categorical crossentropy.<br/>
                                                                    &quot;&quot;&quot;<br/>
                                                                    def __init__(self, input_size, hidden_size, output_size, loss_func=&#x27;mse &#x27;):<br/>
                                                                    self.input_size = input_size<br/>
                                                                    self.hidden_size = hidden_size<br/>
                                                                    self.output_size = output_size<br/>
                                                                    self.loss_func = loss_func<br/>
                                                                    <br/>
                                                                    # Initialize weights and biases<br/>
                                                                    self.weights1 = np.random.randn(self.input_size, self.hidden_size)<br/>
                                                                    self.bias1 = np.zeros((1, self.hidden_size))<br/>
                                                                    self.weights2 = np.random.randn(self.hidden_size, self.output_size)<br/>
                                                                    self.bias2 = np.zeros((1, self.output_size))<br/>
                                                                    <br/>
                                                                    # track loss<br/>
                                                                    self.train_loss = []<br/>
                                                                    self.test_loss = []<br/>
                                                                    <br/>
                                                                    def forward(self, X):<br/>
                                                                    &quot;&quot;&quot;<br/>
                                                                    Perform forward propagation.<br/>
                                                                    <br/>
                                                                    Parameters:<br/>
                                                                    -----------<br/>
                                                                    X: numpy array<br/>
                                                                    The input data<br/>
                                                                    <br/>
                                                                    Returns:<br/>
                                                                    --------<br/>
                                                                    numpy array<br/>
                                                                    The predicted output<br/>
                                                                    &quot;&quot;&quot;<br/>
                                                                    # Perform forward propagation<br/>
                                                                    self.z1 = np.dot(X, self.weights1) + self.bias1<br/>
                                                                    self.a1 = self.sigmoid(self.z1)<br/>
                                                                    self.z2 = np.dot(self.a1, self.weights2) + self.bias2<br/>
                                                                    if self.loss_func == &#x27;categorical_crossentropy &#x27;:<br/>
                                                                    self.a2 = self.softmax(self.z2)<br/>
                                                                    else:<br/>
                                                                    self.a2 = self.sigmoid(self.z2)<br/>
                                                                    return self.a2<br/>
                                                                    <br/>
                                                                    def backward(self, X, y, learning_rate):<br/>
                                                                    &quot;&quot;&quot;<br/>
                                                                    Perform backpropagation.<br/>
                                                                    <br/>
                                                                    Parameters:<br/>
                                                                    -----------<br/>
                                                                    X: numpy array<br/>
                                                                    The input data<br/>
                                                                    y: numpy array<br/>
                                                                    The target output<br/>
                                                                    learning_rate: float<br/>
                                                                    The learning rate<br/>
                                                                    &quot;&quot;&quot;<br/>
                                                                    # Perform backpropagation<br/>
                                                                    m = X.shape[0]<br/>
                                                                    <br/>
                                                                    # Calculate gradients<br/>
                                                                    if self.loss_func == &#x27;mse &#x27;:<br/>
                                                                    self.dz2 = self.a2 - y<br/>
                                                                    elif self.loss_func == &#x27;log_loss &#x27;:<br/>
                                                                    self.dz2 = -(y/self.a2 - (1-y)/(1-self.a2))<br/>
                                                                    elif self.loss_func == &#x27;categorical_crossentropy &#x27;:<br/>
                                                                    self.dz2 = self.a2 - y<br/>
                                                                    else:<br/>
                                                                    raise ValueError(&#x27;Invalid loss function &#x27;)<br/>
                                                                    <br/>
                                                                    self.dw2 = (1 / m) * np.dot(self.a1.T, self.dz2)<br/>
                                                                    self.db2 = (1 / m) * np.sum(self.dz2, axis=0, keepdims=True)<br/>
                                                                    self.dz1 = np.dot(self.dz2, self.weights2.T) * self.sigmoid_derivative(self.a1)<br/>
                                                                    self.dw1 = (1 / m) * np.dot(X.T, self.dz1)<br/>
                                                                    self.db1 = (1 / m) * np.sum(self.dz1, axis=0, keepdims=True)<br/>
                                                                    <br/>
                                                                    # Update weights and biases<br/>
                                                                    self.weights2 -= learning_rate * self.dw2<br/>
                                                                    self.bias2 -= learning_rate * self.db2<br/>
                                                                    self.weights1 -= learning_rate * self.dw1<br/>
                                                                    self.bias1 -= learning_rate * self.db1<br/>
                                                                    <br/>
                                                                    def sigmoid(self, x):<br/>
                                                                    &quot;&quot;&quot;<br/>
                                                                    Sigmoid activation function.<br/>
                                                                    <br/>
                                                                    Parameters:<br/>
                                                                    -----------<br/>
                                                                    x: numpy array<br/>
                                                                    The input data<br/>
                                                                    <br/>
                                                                    Returns:<br/>
                                                                    --------<br/>
                                                                    numpy array<br/>
                                                                    The output of the sigmoid function<br/>
                                                                    &quot;&quot;&quot;<br/>
                                                                    return 1 / (1 + np.exp(-x))<br/>
                                                                    <br/>
                                                                    def sigmoid_derivative(self, x):<br/>
                                                                    &quot;&quot;&quot;<br/>
                                                                    Derivative of the sigmoid activation function.<br/>
                                                                    <br/>
                                                                    Parameters:<br/>
                                                                    -----------<br/>
                                                                    x: numpy array<br/>
                                                                    The input data<br/>
                                                                    <br/>
                                                                    Returns:<br/>
                                                                    --------<br/>
                                                                    numpy array<br/>
                                                                    The output of the derivative of the sigmoid function<br/>
                                                                    &quot;&quot;&quot;<br/>
                                                                    return x * (1 - x)<br/>
                                                                    <br/>
                                                                    def softmax(self, x):<br/>
                                                                    &quot;&quot;&quot;<br/>
                                                                    Softmax activation function.<br/>
                                                                    <br/>
                                                                    Parameters:<br/>
                                                                    -----------<br/>
                                                                    x: numpy array<br/>
                                                                    The input data<br/>
                                                                    <br/>
                                                                    Returns:<br/>
                                                                    --------<br/>
                                                                    numpy array<br/>
                                                                    The output of the softmax function<br/>
                                                                    &quot;&quot;&quot;<br/>
                                                                    exps = np.exp(x - np.max(x, axis=1, keepdims=True))<br/>return exps/np.sum(exps, axis=1, keepdims=True)
                                                                </span>
                                                            </pre>
                                                            <p id="82f9" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <em class="rl">Initialization</em>
                                                            </p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="aaa1" class="tl pm gu ti b bf tm tn l to tp">
                                                                    def __init__(self, input_size, hidden_size, output_size, loss_func=&#x27;mse &#x27;):<br/>
                                                                    self.input_size = input_size<br/>
                                                                    self.hidden_size = hidden_size<br/>
                                                                    self.output_size = output_size<br/>
                                                                    self.loss_func = loss_func<br/>
                                                                    <br/>
                                                                    # Initialize weights and biases<br/>
                                                                    self.weights1 = np.random.randn(self.input_size, self.hidden_size)<br/>
                                                                    self.bias1 = np.zeros((1, self.hidden_size))<br/>
                                                                    self.weights2 = np.random.randn(self.hidden_size, self.output_size)<br/>
                                                                    self.bias2 = np.zeros((1, self.output_size))<br/>
                                                                    <br/>
                                                                    # track loss<br/>
                                                                    self.train_loss = []<br/>self.test_loss = []
                                                                </span>
                                                            </pre>
                                                            <p id="ffe8" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                The <code class="cw tq tr ts ti b">__init__</code>
                                                                method initializes a new instance of the <code class="cw tq tr ts ti b">NeuralNetwork</code>
                                                                class. It takes the size of the input layer (<code class="cw tq tr ts ti b">input_size</code>
                                                                ), the hidden layer (<code class="cw tq tr ts ti b">hidden_size</code>
                                                                ), and the output layer (<code class="cw tq tr ts ti b">output_size</code>
                                                                ) as arguments, along with the type of loss function to use (<code class="cw tq tr ts ti b">loss_func</code>
                                                                ), which defaults to mean squared error (&#x27;mse &#x27;).
                                                            </p>
                                                            <p id="d423" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                Inside this method, the networks weights and biases are initialized. <code class="cw tq tr ts ti b">weights1</code>
                                                                connects the input layer to the hidden layer, and <code class="cw tq tr ts ti b">weights2</code>
                                                                connects the hidden layer to the output layer. The biases (<code class="cw tq tr ts ti b">bias1</code>
                                                                and <code class="cw tq tr ts ti b">bias2</code>
                                                                ) are initialized to zero arrays. This initialization uses random numbers for weights to break symmetry and zeros for biases as a starting point.
                                                            </p>
                                                            <p id="f690" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                It also initializes two lists, <code class="cw tq tr ts ti b">train_loss</code>
                                                                and <code class="cw tq tr ts ti b">test_loss</code>
                                                                , to track the loss during the training and testing phases, respectively.
                                                            </p>
                                                            <p id="3aa0" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <em class="rl">Forward Propagation (</em>
                                                                <code class="cw tq tr ts ti b">
                                                                    <em class="rl">forward</em>
                                                                </code>
                                                                <em class="rl">method)</em>
                                                            </p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="abb6" class="tl pm gu ti b bf tm tn l to tp">
                                                                    def forward(self, X):<br/>
                                                                    # Perform forward propagation<br/>
                                                                    self.z1 = np.dot(X, self.weights1) + self.bias1<br/>
                                                                    self.a1 = self.sigmoid(self.z1)<br/>
                                                                    self.z2 = np.dot(self.a1, self.weights2) + self.bias2<br/>
                                                                    if self.loss_func == &#x27;categorical_crossentropy &#x27;:<br/>
                                                                    self.a2 = self.softmax(self.z2)<br/>
                                                                    else:<br/>
                                                                    self.a2 = self.sigmoid(self.z2)<br/>return self.a2
                                                                </span>
                                                            </pre>
                                                            <p id="6cbc" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                The <code class="cw tq tr ts ti b">forward</code>
                                                                method takes the input data <code class="cw tq tr ts ti b">X</code>
                                                                and passes it through the network. It calculates the weighted sums (<code class="cw tq tr ts ti b">z1</code>
                                                                , <code class="cw tq tr ts ti b">z2</code>
                                                                ) and applies the activation function (sigmoid or softmax, depending on the loss function) to these sums to get the activations (<code class="cw tq tr ts ti b">a1</code>
                                                                , <code class="cw tq tr ts ti b">a2</code>
                                                                ).
                                                            </p>
                                                            <p id="1337" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">For the hidden layer, it always uses the sigmoid activation function. For the output layer, it uses softmax if the loss function is categorical_crossentropy and sigmoid otherwise. The choice between sigmoid and softmax depends on the nature of the task (binary/multi-class classification).</p>
                                                            <p id="16ff" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                This method returns the final output (<code class="cw tq tr ts ti b">a2</code>
                                                                ) of the network, which can be used to make predictions.
                                                            </p>
                                                            <p id="8d4c" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <em class="rl">Backpropagation (</em>
                                                                <code class="cw tq tr ts ti b">
                                                                    <em class="rl">backward</em>
                                                                </code>
                                                                <em class="rl">method)</em>
                                                            </p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="c4af" class="tl pm gu ti b bf tm tn l to tp">
                                                                    def backward(self, X, y, learning_rate):<br/>
                                                                    # Perform backpropagation<br/>
                                                                    m = X.shape[0]<br/>
                                                                    <br/>
                                                                    # Calculate gradients<br/>
                                                                    if self.loss_func == &#x27;mse &#x27;:<br/>
                                                                    self.dz2 = self.a2 - y<br/>
                                                                    elif self.loss_func == &#x27;log_loss &#x27;:<br/>
                                                                    self.dz2 = -(y/self.a2 - (1-y)/(1-self.a2))<br/>
                                                                    elif self.loss_func == &#x27;categorical_crossentropy &#x27;:<br/>
                                                                    self.dz2 = self.a2 - y<br/>
                                                                    else:<br/>
                                                                    raise ValueError(&#x27;Invalid loss function &#x27;)<br/>
                                                                    <br/>
                                                                    self.dw2 = (1 / m) * np.dot(self.a1.T, self.dz2)<br/>
                                                                    self.db2 = (1 / m) * np.sum(self.dz2, axis=0, keepdims=True)<br/>
                                                                    self.dz1 = np.dot(self.dz2, self.weights2.T) * self.sigmoid_derivative(self.a1)<br/>
                                                                    self.dw1 = (1 / m) * np.dot(X.T, self.dz1)<br/>
                                                                    self.db1 = (1 / m) * np.sum(self.dz1, axis=0, keepdims=True)<br/>
                                                                    <br/>
                                                                    # Update weights and biases<br/>
                                                                    self.weights2 -= learning_rate * self.dw2<br/>
                                                                    self.bias2 -= learning_rate * self.db2<br/>
                                                                    self.weights1 -= learning_rate * self.dw1<br/>self.bias1 -= learning_rate * self.db1
                                                                </span>
                                                            </pre>
                                                            <p id="fe71" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                The <code class="cw tq tr ts ti b">backward</code>
                                                                method implements the backpropagation algorithm, which is used to update the weights and biases in the network based on the error between the predicted output and the actual output (<code class="cw tq tr ts ti b">y</code>
                                                                ).
                                                            </p>
                                                            <p id="3897" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                It calculates the gradients of the loss function for the weights and biases (<code class="cw tq tr ts ti b">dw2</code>
                                                                , <code class="cw tq tr ts ti b">db2</code>
                                                                , <code class="cw tq tr ts ti b">dw1</code>
                                                                , <code class="cw tq tr ts ti b">db1</code>
                                                                ) using the chain rule. The gradients indicate how much the weights and biases need to be adjusted to minimize the error.
                                                            </p>
                                                            <p id="7e23" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                The learning rate (<code class="cw tq tr ts ti b">learning_rate</code>
                                                                ) controls how big of a step is taken during the update. The method then updates the weights and biases by subtracting the product of the learning rate and their respective gradients.
                                                            </p>
                                                            <p id="1617" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Different gradient calculations are performed based on the chosen loss function, illustrating the flexibility of the network to adapt to various tasks.</p>
                                                            <p id="3223" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <em class="rl">Activation Functions (</em>
                                                                <code class="cw tq tr ts ti b">
                                                                    <em class="rl">sigmoid</em>
                                                                </code>
                                                                <em class="rl">, </em>
                                                                <code class="cw tq tr ts ti b">
                                                                    <em class="rl">sigmoid_derivative</em>
                                                                </code>
                                                                <em class="rl">, </em>
                                                                <code class="cw tq tr ts ti b">
                                                                    <em class="rl">softmax</em>
                                                                </code>
                                                                <em class="rl">methods)</em>
                                                            </p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="ddbb" class="tl pm gu ti b bf tm tn l to tp">
                                                                    def sigmoid(self, x):<br/>
                                                                    return 1 / (1 + np.exp(-x))<br/>
                                                                    <br/>
                                                                    def sigmoid_derivative(self, x):<br/>
                                                                    return x * (1 - x)<br/>
                                                                    <br/>
                                                                    def softmax(self, x):<br/>
                                                                    exps = np.exp(x - np.max(x, axis=1, keepdims=True))<br/>return exps/np.sum(exps, axis=1, keepdims=True)
                                                                </span>
                                                            </pre>
                                                            <p id="31d0" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <code class="cw tq tr ts ti b">sigmoid</code>
                                                                : This method implements the sigmoid activation function, which squashes the input values into a range between 0 and 1. It &#x27;s particularly useful for binary classification problems.
                                                            </p>
                                                            <p id="7f84" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <code class="cw tq tr ts ti b">sigmoid_derivative</code>
                                                                : This computes the derivative of the sigmoid function, used during backpropagation to calculate gradients.
                                                            </p>
                                                            <p id="1265" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <code class="cw tq tr ts ti b">softmax</code>
                                                                : The softmax function is used for multi-class classification problems. It converts scores from the network into probabilities by taking the exponent of each output and then normalizing these values so that they sum up to 1.
                                                            </p>
                                                            <p id="8a2f" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">
                                                                    Trainer Class<br/>
                                                                </strong>
                                                                The code below introduces a <code class="cw tq tr ts ti b">Trainer</code>
                                                                class designed to train a neural network model. It encapsulates everything needed to conduct training, including executing training cycles (epochs), calculating loss, and adjusting the model &#x27;s parameters through backpropagation based on the loss.
                                                            </p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="2f26" class="tl pm gu ti b bf tm tn l to tp">
                                                                    class Trainer:<br/>
                                                                    &quot;&quot;&quot;<br/>
                                                                    A class to train a neural network.<br/>
                                                                    <br/>
                                                                    Parameters:<br/>
                                                                    -----------<br/>
                                                                    model: NeuralNetwork<br/>
                                                                    The neural network model to train<br/>
                                                                    loss_func: str<br/>
                                                                    The loss function to use. Options are &#x27;mse &#x27;for mean squared error, &#x27;log_loss &#x27;for logistic loss, and &#x27;categorical_crossentropy &#x27;for categorical crossentropy.<br/>
                                                                    &quot;&quot;&quot;<br/>
                                                                    def __init__(self, model, loss_func=&#x27;mse &#x27;):<br/>
                                                                    self.model = model<br/>
                                                                    self.loss_func = loss_func<br/>
                                                                    self.train_loss = []<br/>
                                                                    self.test_loss = []<br/>
                                                                    <br/>
                                                                    def calculate_loss(self, y_true, y_pred):<br/>
                                                                    &quot;&quot;&quot;<br/>
                                                                    Calculate the loss.<br/>
                                                                    <br/>
                                                                    Parameters:<br/>
                                                                    -----------<br/>
                                                                    y_true: numpy array<br/>
                                                                    The true output<br/>
                                                                    y_pred: numpy array<br/>
                                                                    The predicted output<br/>
                                                                    <br/>
                                                                    Returns:<br/>
                                                                    --------<br/>
                                                                    float<br/>
                                                                    The loss<br/>
                                                                    &quot;&quot;&quot;<br/>
                                                                    if self.loss_func == &#x27;mse &#x27;:<br/>
                                                                    return np.mean((y_pred - y_true)**2)<br/>
                                                                    elif self.loss_func == &#x27;log_loss &#x27;:<br/>
                                                                    return -np.mean(y_true*np.log(y_pred) + (1-y_true)*np.log(1-y_pred))<br/>
                                                                    elif self.loss_func == &#x27;categorical_crossentropy &#x27;:<br/>
                                                                    return -np.mean(y_true*np.log(y_pred))<br/>
                                                                    else:<br/>
                                                                    raise ValueError(&#x27;Invalid loss function &#x27;)<br/>
                                                                    <br/>
                                                                    def train(self, X_train, y_train, X_test, y_test, epochs, learning_rate):<br/>
                                                                    &quot;&quot;&quot;<br/>
                                                                    Train the neural network.<br/>
                                                                    <br/>
                                                                    Parameters:<br/>
                                                                    -----------<br/>
                                                                    X_train: numpy array<br/>
                                                                    The training input data<br/>
                                                                    y_train: numpy array<br/>
                                                                    The training target output<br/>
                                                                    X_test: numpy array<br/>
                                                                    The test input data<br/>
                                                                    y_test: numpy array<br/>
                                                                    The test target output<br/>
                                                                    epochs: int<br/>
                                                                    The number of epochs to train the model<br/>
                                                                    learning_rate: float<br/>
                                                                    The learning rate<br/>
                                                                    &quot;&quot;&quot;<br/>
                                                                    for _ in range(epochs):<br/>
                                                                    self.model.forward(X_train)<br/>
                                                                    self.model.backward(X_train, y_train, learning_rate)<br/>
                                                                    train_loss = self.calculate_loss(y_train, self.model.a2)<br/>
                                                                    self.train_loss.append(train_loss)<br/>
                                                                    <br/>
                                                                    self.model.forward(X_test)<br/>
                                                                    test_loss = self.calculate_loss(y_test, self.model.a2)<br/>self.test_loss.append(test_loss)
                                                                </span>
                                                            </pre>
                                                            <p id="47b3" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Here &#x27;s a detailed breakdown of the class and its methods:</p>
                                                            <p id="c6eb" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <em class="rl">Class Initialization (</em>
                                                                <code class="cw tq tr ts ti b">
                                                                    <em class="rl">__init__</em>
                                                                </code>
                                                                <em class="rl">method)</em>
                                                            </p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="6b6e" class="tl pm gu ti b bf tm tn l to tp">
                                                                    def __init__(self, model, loss_func=&#x27;mse &#x27;):<br/>
                                                                    self.model = model<br/>
                                                                    self.loss_func = loss_func<br/>
                                                                    self.train_loss = []<br/>self.test_loss = []
                                                                </span>
                                                            </pre>
                                                            <p id="7994" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                The constructor takes a neural network model (<code class="cw tq tr ts ti b">model</code>
                                                                ) and a loss function (<code class="cw tq tr ts ti b">loss_func</code>
                                                                ) as inputs. The <code class="cw tq tr ts ti b">loss_func</code>
                                                                defaults to mean squared error (&#x27;mse &#x27;) if not specified.
                                                            </p>
                                                            <p id="9c32" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                It initializes <code class="cw tq tr ts ti b">train_loss</code>
                                                                and <code class="cw tq tr ts ti b">test_loss</code>
                                                                lists to keep track of the loss values during the training and testing phases, allowing for monitoring of the model &#x27;s performance over time.
                                                            </p>
                                                            <p id="9d29" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <em class="rl">Calculating Loss (</em>
                                                                <code class="cw tq tr ts ti b">
                                                                    <em class="rl">calculate_loss</em>
                                                                </code>
                                                                <em class="rl">method)</em>
                                                            </p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="8c75" class="tl pm gu ti b bf tm tn l to tp">
                                                                    def calculate_loss(self, y_true, y_pred):<br/>
                                                                    if self.loss_func == &#x27;mse &#x27;:<br/>
                                                                    return np.mean((y_pred - y_true)**2)<br/>
                                                                    elif self.loss_func == &#x27;log_loss &#x27;:<br/>
                                                                    return -np.mean(y_true*np.log(y_pred) + (1-y_true)*np.log(1-y_pred))<br/>
                                                                    elif self.loss_func == &#x27;categorical_crossentropy &#x27;:<br/>
                                                                    return -np.mean(y_true*np.log(y_pred))<br/>
                                                                    else:<br/>raise ValueError(&#x27;Invalid loss function &#x27;)
                                                                </span>
                                                            </pre>
                                                            <p id="0bd0" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                This method calculates the loss between the predicted outputs (<code class="cw tq tr ts ti b">y_pred</code>
                                                                ) and the true outputs (<code class="cw tq tr ts ti b">y_true</code>
                                                                ) using the specified loss function. This is crucial for evaluating how well the model is performing and for performing backpropagation.
                                                            </p>
                                                            <p id="9832" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">The method supports three types of loss functions:</p>
                                                            <ul class="">
                                                                <li id="761a" class="og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb ri rj rk bj">
                                                                    <em class="rl">Mean Squared Error (mse)</em>
                                                                    : Used for regression tasks, calculating the average of the squares of the differences between predicted and true values.
                                                                </li>
                                                                <li id="c08c" class="og oh gu oi b hs rm ok ol hv rn on oo op ro or os ot rp ov ow ox rq oz pa pb ri rj rk bj">
                                                                    <em class="rl">Logistic Loss (log_loss)</em>
                                                                    : Suited for binary classification problems, computing the loss using the log-likelihood method.
                                                                </li>
                                                                <li id="5f7e" class="og oh gu oi b hs rm ok ol hv rn on oo op ro or os ot rp ov ow ox rq oz pa pb ri rj rk bj">
                                                                    <em class="rl">Categorical Crossentropy (categorical_crossentropy):</em>
                                                                    Ideal for multi-class classification tasks, measuring the discrepancy between true labels and predictions.
                                                                </li>
                                                            </ul>
                                                            <p id="9672" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                If an invalid loss function is provided, it raises a <code class="cw tq tr ts ti b">ValueError</code>
                                                                .
                                                            </p>
                                                            <p id="6aee" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <em class="rl">Training the Model (</em>
                                                                <code class="cw tq tr ts ti b">
                                                                    <em class="rl">train</em>
                                                                </code>
                                                                <em class="rl">method)</em>
                                                            </p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="94de" class="tl pm gu ti b bf tm tn l to tp">
                                                                    def train(self, X_train, y_train, X_test, y_test, epochs, learning_rate):<br/>
                                                                    for _ in range(epochs):<br/>
                                                                    self.model.forward(X_train)<br/>
                                                                    self.model.backward(X_train, y_train, learning_rate)<br/>
                                                                    train_loss = self.calculate_loss(y_train, self.model.a2)<br/>
                                                                    self.train_loss.append(train_loss)<br/>
                                                                    <br/>
                                                                    self.model.forward(X_test)<br/>
                                                                    test_loss = self.calculate_loss(y_test, self.model.a2)<br/>self.test_loss.append(test_loss)
                                                                </span>
                                                            </pre>
                                                            <p id="6d48" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                The <code class="cw tq tr ts ti b">train</code>
                                                                method manages the training process over a specified number of epochs using the training (<code class="cw tq tr ts ti b">X_train</code>
                                                                , <code class="cw tq tr ts ti b">y_train</code>
                                                                ) and testing datasets (<code class="cw tq tr ts ti b">X_test</code>
                                                                , <code class="cw tq tr ts ti b">y_test</code>
                                                                ). It also takes a <code class="cw tq tr ts ti b">learning_rate</code>
                                                                parameter that influences the step size in the parameter update during backpropagation.
                                                            </p>
                                                            <p id="23e0" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">For each epoch (training cycle), the method performs the following steps:</p>
                                                            <ol class="">
                                                                <li id="3546" class="og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb tt rj rk bj">
                                                                    <em class="rl">Forward Pass on Training Data</em>
                                                                    : It uses the models <code class="cw tq tr ts ti b">forward</code>
                                                                    method to compute the predicted outputs for the training data.
                                                                </li>
                                                                <li id="5d88" class="og oh gu oi b hs rm ok ol hv rn on oo op ro or os ot rp ov ow ox rq oz pa pb tt rj rk bj">
                                                                    <em class="rl">Backward Pass (Parameter Update)</em>
                                                                    : It applies the models <code class="cw tq tr ts ti b">backward</code>
                                                                    method using the training data and labels (<code class="cw tq tr ts ti b">y_train</code>
                                                                    ) along with the <code class="cw tq tr ts ti b">learning_rate</code>
                                                                    to update the model &#x27;s weights and biases based on the gradients calculated from the loss.
                                                                </li>
                                                                <li id="e901" class="og oh gu oi b hs rm ok ol hv rn on oo op ro or os ot rp ov ow ox rq oz pa pb tt rj rk bj">
                                                                    <em class="rl">Calculate Training Loss</em>
                                                                    : The training loss is calculated using the <code class="cw tq tr ts ti b">calculate_loss</code>
                                                                    method with the training labels and the predictions. This loss is then appended to the <code class="cw tq tr ts ti b">train_loss</code>
                                                                    list for monitoring.
                                                                </li>
                                                                <li id="a084" class="og oh gu oi b hs rm ok ol hv rn on oo op ro or os ot rp ov ow ox rq oz pa pb tt rj rk bj">
                                                                    <em class="rl">Forward Pass on Testing Data</em>
                                                                    : Similarly, the method computes predictions for the testing data to evaluate the models performance on unseen data.
                                                                </li>
                                                                <li id="62c8" class="og oh gu oi b hs rm ok ol hv rn on oo op ro or os ot rp ov ow ox rq oz pa pb tt rj rk bj">
                                                                    <em class="rl">Calculate Testing Loss:</em>
                                                                    It calculates the testing loss using the testing labels and predictions, appending this loss to the <code class="cw tq tr ts ti b">test_loss</code>
                                                                    list.
                                                                </li>
                                                            </ol>
                                                            <p id="49e0" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">
                                                                    Implementation<br/>
                                                                </strong>
                                                                In this section, I will outline a complete process for loading a dataset, preparing it for training, and using it to train a neural network for a classification task. The process involves data preprocessing, model creation, training, and evaluation.
                                                            </p>
                                                            <p id="efb1" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                For this task, we will use the <code class="cw tq tr ts ti b">digits</code>
                                                                dataset from the open-source (BSD-3 license) sci-kit learn library. <a class="af pk" href="https://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html" rel="noopener ugc nofollow" target="_blank">Click here for more information about Sci-Kit Learn</a>
                                                                .
                                                            </p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="c7c7" class="tl pm gu ti b bf tm tn l to tp">
                                                                    # Load the digits dataset<br/>
                                                                    digits = load_digits()<br/>
                                                                    <br/>
                                                                    # Preprocess the dataset<br/>
                                                                    scaler = MinMaxScaler()<br/>
                                                                    X = scaler.fit_transform(digits.data)<br/>
                                                                    y = digits.target<br/>
                                                                    <br/>
                                                                    # One-hot encode the target output<br/>
                                                                    encoder = OneHotEncoder(sparse=False)<br/>
                                                                    y_onehot = encoder.fit_transform(y.reshape(-1, 1))<br/>
                                                                    <br/>
                                                                    # Split the dataset into training and testing sets<br/>
                                                                    X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)<br/>
                                                                    <br/>
                                                                    # Create an instance of the NeuralNetwork class<br/>
                                                                    input_size = X.shape[1]<br/>
                                                                    hidden_size = 64<br/>
                                                                    output_size = len(np.unique(y))<br/>
                                                                    loss_func = &#x27;categorical_crossentropy &#x27;<br/>
                                                                    epochs = 1000<br/>
                                                                    learning_rate = 0.1<br/>
                                                                    <br/>
                                                                    nn = NeuralNetwork(input_size, hidden_size, output_size, loss_func)<br/>
                                                                    <br/>
                                                                    trainer = Trainer(nn, loss_func)<br/>
                                                                    trainer.train(X_train, y_train, X_test, y_test, epochs, learning_rate)<br/>
                                                                    <br/>
                                                                    # Convert y_test from one-hot encoding to labels<br/>
                                                                    y_test_labels = np.argmax(y_test, axis=1)<br/>
                                                                    <br/>
                                                                    # Evaluate the performance of the neural network<br/>
                                                                    predictions = np.argmax(nn.forward(X_test), axis=1)<br/>
                                                                    accuracy = np.mean(predictions == y_test_labels)<br/>print(f &quot;Accuracy: {accuracy:.2%}&quot;)
                                                                </span>
                                                            </pre>
                                                            <p id="7ac8" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Lets walk through each step:</p>
                                                            <p id="53ea" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <em class="rl">Load the Dataset</em>
                                                            </p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="a3eb" class="tl pm gu ti b bf tm tn l to tp">
                                                                    # Load the digits dataset<br/>digits = load_digits()
                                                                </span>
                                                            </pre>
                                                            <figure class="nr ns nt nu nv nw no np paragraph-image">
                                                                <div role="button" tabindex="0" class="nx ny fi nz bg oa">
                                                                    <div class="no np tu">
                                                                        <picture>
                                                                            <source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*m4iTf2Bv3Vu3I8ugDoTpNQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*m4iTf2Bv3Vu3I8ugDoTpNQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*m4iTf2Bv3Vu3I8ugDoTpNQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*m4iTf2Bv3Vu3I8ugDoTpNQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*m4iTf2Bv3Vu3I8ugDoTpNQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*m4iTf2Bv3Vu3I8ugDoTpNQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m4iTf2Bv3Vu3I8ugDoTpNQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/>
                                                                            <source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*m4iTf2Bv3Vu3I8ugDoTpNQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*m4iTf2Bv3Vu3I8ugDoTpNQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*m4iTf2Bv3Vu3I8ugDoTpNQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*m4iTf2Bv3Vu3I8ugDoTpNQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*m4iTf2Bv3Vu3I8ugDoTpNQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*m4iTf2Bv3Vu3I8ugDoTpNQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*m4iTf2Bv3Vu3I8ugDoTpNQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/>
                                                                            <img alt="" class="bg mv ob c" width="700" height="323" loading="lazy" role="presentation"/>
                                                                        </picture>
                                                                    </div>
                                                                </div>
                                                                <figcaption class="oc fe od no np oe of be b bf z dt">Digits Dataset First 10 Images  Image by Author</figcaption>
                                                            </figure>
                                                            <p id="40c9" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                The dataset used here is the <code class="cw tq tr ts ti b">digits</code>
                                                                dataset, which is commonly used for classification tasks involving recognizing handwritten digits.
                                                            </p>
                                                            <p id="1b96" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <em class="rl">Preprocess the Dataset</em>
                                                            </p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="a1ee" class="tl pm gu ti b bf tm tn l to tp">
                                                                    # Preprocess the dataset<br/>
                                                                    scaler = MinMaxScaler()<br/>
                                                                    X = scaler.fit_transform(digits.data)<br/>y = digits.target
                                                                </span>
                                                            </pre>
                                                            <p id="2a29" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                The features of the dataset are scaled to a range between 0 and 1 using the <code class="cw tq tr ts ti b">MinMaxScaler</code>
                                                                . This is a common preprocessing step to ensure that all input features have the same scale, which can help the neural network learn more effectively.
                                                            </p>
                                                            <p id="beb1" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                The scaled features are stored in <code class="cw tq tr ts ti b">X</code>
                                                                , and the target labels (which digit each image represents) are stored in <code class="cw tq tr ts ti b">y</code>
                                                                .
                                                            </p>
                                                            <p id="a702" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <em class="rl">One-hot Encode the Target Output</em>
                                                            </p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="a189" class="tl pm gu ti b bf tm tn l to tp">
                                                                    # One-hot encode the target output<br/>
                                                                    encoder = OneHotEncoder(sparse=False)<br/>y_onehot = encoder.fit_transform(y.reshape(-1, 1))
                                                                </span>
                                                            </pre>
                                                            <p id="423c" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                Since this is a classification task with multiple classes, the target labels are one-hot encoded using <code class="cw tq tr ts ti b">OneHotEncoder</code>
                                                                . One-hot encoding transforms the categorical target data into a format that &#x27;s easier for neural networks to understand and work with, especially for classification tasks.
                                                            </p>
                                                            <p id="36ce" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <em class="rl">Split the Dataset</em>
                                                            </p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="5711" class="tl pm gu ti b bf tm tn l to tp">
                                                                    # Split the dataset into training and testing sets<br/>X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)
                                                                </span>
                                                            </pre>
                                                            <p id="e6dd" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                The dataset is split into training and testing sets using <code class="cw tq tr ts ti b">train_test_split</code>
                                                                , with 80% of the data used for training and 20% for testing. This split allows for training the model on one portion of the data and then evaluating its performance on a separate, unseen portion to check how well it generalizes.
                                                            </p>
                                                            <p id="cb61" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <em class="rl">Create an Instance of the NeuralNetwork Class</em>
                                                            </p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="7679" class="tl pm gu ti b bf tm tn l to tp">
                                                                    # Create an instance of the NeuralNetwork class<br/>
                                                                    input_size = X.shape[1]<br/>
                                                                    hidden_size = 64<br/>
                                                                    output_size = len(np.unique(y))<br/>
                                                                    loss_func = &#x27;categorical_crossentropy &#x27;<br/>
                                                                    epochs = 1000<br/>
                                                                    learning_rate = 0.1<br/>
                                                                    <br/>nn = NeuralNetwork(input_size, hidden_size, output_size, loss_func)
                                                                </span>
                                                            </pre>
                                                            <p id="c3b6" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">A neural network instance is created with specified input size (the number of features), hidden size (the number of neurons in the hidden layer), output size (the number of unique labels), and the loss function to use. The input size matches the number of features, the output size matches the number of unique target classes, and a hidden layer size is chosen.</p>
                                                            <p id="3693" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <em class="rl">Training the Neural Network</em>
                                                            </p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="4262" class="tl pm gu ti b bf tm tn l to tp">
                                                                    trainer = Trainer(nn, loss_func)<br/>trainer.train(X_train, y_train, X_test, y_test, epochs, learning_rate)
                                                                </span>
                                                            </pre>
                                                            <p id="7fa3" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                An instance of the <code class="cw tq tr ts ti b">Trainer</code>
                                                                class is created with the neural network and loss function. The <code class="cw tq tr ts ti b">train</code>
                                                                method is then called with the training and testing datasets, along with the number of epochs and the learning rate specified. This process iteratively adjusts the neural network &#x27;s weights and biases to minimize the loss function, using the training data for learning and the testing data for validation.
                                                            </p>
                                                            <p id="3348" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <em class="rl">Evaluate the Performance</em>
                                                            </p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="f339" class="tl pm gu ti b bf tm tn l to tp">
                                                                    # Convert y_test from one-hot encoding to labels<br/>
                                                                    y_test_labels = np.argmax(y_test, axis=1)<br/>
                                                                    <br/>
                                                                    # Evaluate the performance of the neural network<br/>
                                                                    predictions = np.argmax(nn.forward(X_test), axis=1)<br/>
                                                                    accuracy = np.mean(predictions == y_test_labels)<br/>print(f &quot;Accuracy: {accuracy:.2%}&quot;)
                                                                </span>
                                                            </pre>
                                                            <p id="f03d" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                After training, the models performance is evaluated on the test set. Since the targets were one-hot encoded, <code class="cw tq tr ts ti b">np.argmax</code>
                                                                is used to convert the one-hot encoded predictions back to label form. The accuracy of the model is calculated by comparing these predicted labels against the actual labels (<code class="cw tq tr ts ti b">y_test_labels</code>
                                                                ) and then printed out.
                                                            </p>
                                                            <p id="313e" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Now, this code lacks a few activation functions we talked about, improvements such as SGD or Adam Optimizer, and more. I leave this to you to take and make this code your own, by filling the gaps with your code. In this way, you will truly master Neural Networks.</p>
                                                            <h2 id="f6d9" class="qh pm gu be pn qi qj dx pq qk ql dz pt op qm qn qo ot qp qq qr ox qs qt qu qv bj">4.2: Utilizing Libraries for Neural Network Implementation (TensorFlow)</h2>
                                                            <p id="6fa8" class="pw-post-body-paragraph og oh gu oi b hs qw ok ol hv qx on oo op qy or os ot qz ov ow ox ra oz pa pb gn bj">Well, that was a lot! Luckily for us, we dont need to write such a long code every time we want to work with NNs. We can leverage libraries such as Tensorflow and PyTorch which will create Deep Learning models for us with minimum code. In this example, we will create and explain a TensorFlow version of training a neural network on the digits dataset, similar to the process described previously.</p>
                                                            <p id="f378" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">As before lets first import the required libraries, and the dataset and lets preprocess it, in the same fashion we did before.</p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="95fa" class="tl pm gu ti b bf tm tn l to tp">
                                                                    import tensorflow as tf<br/>
                                                                    from sklearn.datasets import load_digits<br/>
                                                                    from sklearn.model_selection import train_test_split<br/>
                                                                    from sklearn.preprocessing import MinMaxScaler, OneHotEncoder<br/>
                                                                    <br/>
                                                                    # Load the digits dataset<br/>
                                                                    digits = load_digits()<br/>
                                                                    <br/>
                                                                    # Scale the features to a range between 0 and 1<br/>
                                                                    scaler = MinMaxScaler()<br/>
                                                                    X_scaled = scaler.fit_transform(digits.data)<br/>
                                                                    <br/>
                                                                    # One-hot encode the target labels<br/>
                                                                    encoder = OneHotEncoder(sparse=False)<br/>
                                                                    y_onehot = encoder.fit_transform(digits.target.reshape(-1, 1))<br/>
                                                                    <br/>
                                                                    # Split the dataset into training and testing sets<br/>X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_onehot, test_size=0.2, random_state=42)
                                                                </span>
                                                            </pre>
                                                            <p id="3320" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Secondly, lets build the NN:</p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="8992" class="tl pm gu ti b bf tm tn l to tp">
                                                                    # Define the model architecture<br/>
                                                                    model = tf.keras.models.Sequential([<br/>
                                                                    tf.keras.layers.Dense(64, activation=&#x27;relu &#x27;, input_shape=(X_train.shape[1],)),<br/>
                                                                    tf.keras.layers.Dense(len(np.unique(digits.target)), activation=&#x27;softmax &#x27;)<br/>])
                                                                </span>
                                                            </pre>
                                                            <p id="d9ba" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                Here, a <code class="cw tq tr ts ti b">Sequential</code>
                                                                model is created, indicating a linear stack of layers.
                                                            </p>
                                                            <p id="afd7" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                The first layer is a densely-connected layer with 64 units (neurons) and ReLU activation. It expects input from the shape <code class="cw tq tr ts ti b">(X_train.shape[1],)</code>
                                                                , which matches the number of features in the dataset.
                                                            </p>
                                                            <p id="b1b7" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">The output layer has several units equal to the number of unique target classes and uses the softmax activation function to output probabilities for each class.</p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="a71a" class="tl pm gu ti b bf tm tn l to tp">
                                                                    # Compile the model<br/>
                                                                    model.compile(optimizer=&#x27;adam &#x27;,<br/>
                                                                    loss=&#x27;categorical_crossentropy &#x27;,<br/>metrics=[&#x27;accuracy &#x27;])
                                                                </span>
                                                            </pre>
                                                            <p id="066c" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">The model is compiled with the Adam optimizer and categorical cross-entropy as the loss function, suitable for multi-class classification tasks. Accuracy is specified as a metric for evaluation.</p>
                                                            <p id="c3f5" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Lastly, lets train and evaluate the performance of our NN:</p>
                                                            <pre class="nr ns nt nu nv th ti tj bo tk ba bj">
                                                                <span id="1670" class="tl pm gu ti b bf tm tn l to tp">
                                                                    # Train the model<br/>
                                                                    history = model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test), verbose=2)<br/>
                                                                    <br/>
                                                                    # Evaluate the model on the test set<br/>
                                                                    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)<br/>print(f &quot;Test accuracy: {test_accuracy:.2%}&quot;)
                                                                </span>
                                                            </pre>
                                                            <p id="8d35" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                The model is trained using the <code class="cw tq tr ts ti b">fit</code>
                                                                method with 1000 epochs, and the testing set is used as validation data. <code class="cw tq tr ts ti b">verbose=2</code>
                                                                indicates that one line per epoch will be printed for logging.
                                                            </p>
                                                            <p id="db4b" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                Finally, the models performance is evaluated on the test set using the <code class="cw tq tr ts ti b">evaluate</code>
                                                                method, and the test accuracy is printed.
                                                            </p>
                                                            <h1 id="2a21" class="pl pm gu be pn po rb hu pq pr rc hx pt pu rd pw px py re qa qb qc rf qe qf qg bj">5: Challenges</h1>
                                                            <h2 id="2a8a" class="qh pm gu be pn qi qj dx pq qk ql dz pt op qm qn qo ot qp qq qr ox qs qt qu qv bj">5.1: Overcoming Overfitting</h2>
                                                            <p id="a232" class="pw-post-body-paragraph og oh gu oi b hs qw ok ol hv qx on oo op qy or os ot qz ov ow ox ra oz pa pb gn bj">Overfitting is like when a neural network becomes a bit too obsessed with its training data, picking up on all the tiny details and noise, to the point where it struggles to handle new, unseen data. Its like studying so hard for your exams by memorizing the textbook word for word but then not being able to apply what youve learned to any question thats phrased differently. This problem can hold back a models ability to perform well in real-world situations, where being able to generalize or apply what its learned to new scenarios, is key. Luckily, there are several clever techniques to help prevent or lessen overfitting, making our models more versatile and ready for the real world. Lets take a look at a few of them, but dont worry about mastering all of them now as I will cover anti-overfitting techniques in a separate article.</p>
                                                            <p id="3f61" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">Dropout</strong>
                                                                : This is like randomly turning off some of the neurons in the network during training. It stops the neurons from getting too dependent on each other, forcing the network to learn more robust features that arent just relying on a specific set of neurons to make predictions.
                                                            </p>
                                                            <p id="7788" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">
                                                                    Early Stopping<br/>
                                                                </strong>
                                                                This involves watching how the model does on a validation set (a separate chunk of data) as its training. If the model starts doing worse on this set, its a sign that its beginning to overfit, and its time to stop training.
                                                            </p>
                                                            <p id="b76f" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">
                                                                    Using a Validation Set<br/>
                                                                </strong>
                                                                Dividing your data into three sets  training, validation, and test  helps keep an eye on overfitting. The validation set is for tuning the model and picking the best version, while the test set gives you a fair assessment of how well the model is doing.
                                                            </p>
                                                            <p id="7ae7" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">
                                                                <strong class="oi gv">
                                                                    Simplifying The Model<br/>
                                                                </strong>
                                                                Sometimes, less is more. If a model is too complex, it might start picking up noise from the training data. By choosing a simpler model or dialing back on the number of layers, we can reduce the risk of overfitting.
                                                            </p>
                                                            <p id="45bd" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">As you experiment with NN, you will see that fine-tuning and tackling overfitting will play a pivotal role in NNs performance. Making sure you master anti-overfitting techniques is a must for a successful data scientist. Because of its importance, I will dedicate an entire article to these techniques to make sure you can fine-tune the best NNs and guarantee an optimal performance for your projects.</p>
                                                            <h1 id="f035" class="pl pm gu be pn po rb hu pq pr rc hx pt pu rd pw px py re qa qb qc rf qe qf qg bj">6: Conclusion</h1>
                                                            <p id="cf73" class="pw-post-body-paragraph og oh gu oi b hs qw ok ol hv qx on oo op qy or os ot qz ov ow ox ra oz pa pb gn bj">Diving into the world of neural networks opens our eyes to the incredible potential these models hold within the realm of artificial intelligence. Starting with the basics, like how neural networks use weighted sums and activation functions to process information, weve seen how techniques like backpropagation and gradient descent empower them to learn from data. Especially in areas like image recognition, weve witnessed firsthand how neural networks are solving complex challenges and pushing technology forward.</p>
                                                            <p id="1781" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">Looking ahead, its clear we are only at the beginning of a long journey called Deep Learning. In the next articles, we will talk about more advanced deep learning architectures, fine-tuning methods, and much more!</p>
                                                            <h1 id="62f9" class="pl pm gu be pn po rb hu pq pr rc hx pt pu rd pw px py re qa qb qc rf qe qf qg bj">Bibliography</h1>
                                                            <ol class="">
                                                                <li id="aa1d" class="og oh gu oi b hs qw ok ol hv qx on oo op qy or os ot qz ov ow ox ra oz pa pb tt rj rk bj">Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. Deep Learning. MIT Press, 2016. This comprehensive textbook provides an extensive overview of deep learning, covering the mathematical underpinnings and practical aspects of neural networks.</li>
                                                                <li id="56b9" class="og oh gu oi b hs rm ok ol hv rn on oo op ro or os ot rp ov ow ox rq oz pa pb tt rj rk bj">LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature 521, no. 7553 (2015): 436444. A landmark paper by pioneers in the field, summarizing the key concepts and achievements in deep learning and neural networks.</li>
                                                            </ol>
                                                        </div>
                                                    </div>
                                                </div>
                                                <div class="ab ca pc pd pe pf" role="separator">
                                                    <span class="pg bx bl ph pi pj"></span>
                                                    <span class="pg bx bl ph pi pj"></span>
                                                    <span class="pg bx bl ph pi"></span>
                                                </div>
                                                <div class="gn go gp gq gr">
                                                    <div class="ab ca">
                                                        <div class="ch bg fz ga gb gc">
                                                            <p id="595c" class="pw-post-body-paragraph og oh gu oi b hs oj ok ol hv om on oo op oq or os ot ou ov ow ox oy oz pa pb gn bj">You made it to the end. Congrats! I hope you enjoyed this article, if so consider leaving a like and following me, as I will regularly post similar articles. My goal is to recreate all the most popular algorithms from scratch and make machine learning accessible to everyone.</p>
                                                        </div>
                                                    </div>
                                                </div>
                                            </div>
                                        </section>
                                    </div>
                                </div>
                            </article>
                            <div class="ab ca">
                                <div class="ch bg fz ga gb gc"></div>
                            </div>
                        </div>
                        <div class="ab ca">
                            <div class="ch bg fz ga gb gc">
                                <div class="tv tw ab jr">
                                    <div class="sx ab">
                                        <a class="tx ax am ao" href="https://medium.com/tag/deep-learning?source=post_page-----a34a51b93873---------------deep_learning-----------------" rel="noopener follow">
                                            <div class="ty fi cw tz ge ua ub be b bf z bj uc">Deep Learning</div>
                                        </a>
                                    </div>
                                    <div class="sx ab">
                                        <a class="tx ax am ao" href="https://medium.com/tag/data-science?source=post_page-----a34a51b93873---------------data_science-----------------" rel="noopener follow">
                                            <div class="ty fi cw tz ge ua ub be b bf z bj uc">Data Science</div>
                                        </a>
                                    </div>
                                    <div class="sx ab">
                                        <a class="tx ax am ao" href="https://medium.com/tag/machine-learning?source=post_page-----a34a51b93873---------------machine_learning-----------------" rel="noopener follow">
                                            <div class="ty fi cw tz ge ua ub be b bf z bj uc">Machine Learning</div>
                                        </a>
                                    </div>
                                    <div class="sx ab">
                                        <a class="tx ax am ao" href="https://medium.com/tag/mathematics?source=post_page-----a34a51b93873---------------mathematics-----------------" rel="noopener follow">
                                            <div class="ty fi cw tz ge ua ub be b bf z bj uc">Mathematics</div>
                                        </a>
                                    </div>
                                    <div class="sx ab">
                                        <a class="tx ax am ao" href="https://medium.com/tag/deep-dives?source=post_page-----a34a51b93873---------------deep_dives-----------------" rel="noopener follow">
                                            <div class="ty fi cw tz ge ua ub be b bf z bj uc">Deep Dives</div>
                                        </a>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="l"></div>
                        <footer class="ud ue uf ug uh ui uj uk ul ab q um jb c">
                            <div class="l ae">
                                <div class="ab ca">
                                    <div class="ch bg fz ga gb gc">
                                        <div class="ab co un">
                                            <div class="ab q lm">
                                                <div class="uo l">
                                                    <span class="l up uq ur e d">
                                                        <div class="ab q lm ln">
                                                            <div class="pw-multi-vote-icon fi jv lo lp lq">
                                                                <span>
                                                                    <a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa34a51b93873&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-math-behind-neural-networks-a34a51b93873&amp;user=Cristian+Leo&amp;userId=c24a3d106811&amp;source=-----a34a51b93873---------------------clap_footer-----------" rel="noopener follow">
                                                                        <div>
                                                                            <div class="bl" aria-hidden="false">
                                                                                <div class="lr ao ls lt lu lv am lw lx ly lq">
                                                                                    <svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap">
                                                                                        <path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path>
                                                                                    </svg>
                                                                                </div>
                                                                            </div>
                                                                        </div>
                                                                    </a>
                                                                </span>
                                                            </div>
                                                            <div class="pw-multi-vote-count l lz ma mb mc md me mf">
                                                                <p class="be b du z dt">
                                                                    <span class="mg">--</span>
                                                                </p>
                                                            </div>
                                                        </div>
                                                    </span>
                                                    <span class="l h g f us ut">
                                                        <div class="ab q lm ln">
                                                            <div class="pw-multi-vote-icon fi jv lo lp lq">
                                                                <span>
                                                                    <a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa34a51b93873&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-math-behind-neural-networks-a34a51b93873&amp;user=Cristian+Leo&amp;userId=c24a3d106811&amp;source=-----a34a51b93873---------------------clap_footer-----------" rel="noopener follow">
                                                                        <div>
                                                                            <div class="bl" aria-hidden="false">
                                                                                <div class="lr ao ls lt lu lv am lw lx ly lq">
                                                                                    <svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap">
                                                                                        <path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path>
                                                                                    </svg>
                                                                                </div>
                                                                            </div>
                                                                        </div>
                                                                    </a>
                                                                </span>
                                                            </div>
                                                            <div class="pw-multi-vote-count l lz ma mb mc md me mf">
                                                                <p class="be b du z dt">
                                                                    <span class="mg">--</span>
                                                                </p>
                                                            </div>
                                                        </div>
                                                    </span>
                                                </div>
                                                <div class="bp ab">
                                                    <div>
                                                        <div class="bl" aria-hidden="false">
                                                            <button class="ao lr mj mk ab q fj ml mm" aria-label="responses">
                                                                <svg width="24" height="24" viewBox="0 0 24 24" class="mi">
                                                                    <path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path>
                                                                </svg>
                                                                <p class="be b bf z dt">
                                                                    <span class="pw-responses-count mh mi">8</span>
                                                                </p>
                                                            </button>
                                                        </div>
                                                    </div>
                                                </div>
                                            </div>
                                            <div class="ab q">
                                                <div class="pj l jo">
                                                    <div>
                                                        <div class="bl" aria-hidden="false">
                                                            <span>
                                                                <a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa34a51b93873&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-math-behind-neural-networks-a34a51b93873&amp;source=--------------------------bookmark_footer-----------" rel="noopener follow">
                                                                    <svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="dt mo" aria-label="Add to list bookmark button">
                                                                        <path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="currentColor"></path>
                                                                    </svg>
                                                                </a>
                                                            </span>
                                                        </div>
                                                    </div>
                                                </div>
                                                <div class="pj l jo">
                                                    <div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu">
                                                        <div>
                                                            <div class="bl" aria-hidden="false">
                                                                <button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="footerSocialShareButton" class="af fj ah ai aj ak al mw an ao ap ew mx my mm mz">
                                                                    <svg width="24" height="24" viewBox="0 0 24 24" fill="none">
                                                                        <path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path>
                                                                    </svg>
                                                                </button>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </footer>
                        <div class="uu uv uw ux uy l bw">
                            <div class="ab ca">
                                <div class="ch bg fz ga gb gc">
                                    <div class="ck ab uz co">
                                        <div class="ab ir">
                                            <a href="https://medium.com/@cristianleo120?source=post_page-----a34a51b93873--------------------------------" rel="noopener follow">
                                                <div class="l va vb bx vc iv">
                                                    <div class="l fi">
                                                        <img alt="Cristian Leo" class="l fc bx vd ve cw" src="https://miro.medium.com/v2/da:true/resize:fill:144:144/0*vXUpsKuv7A7DlqP0" width="72" height="72" loading="lazy"/>
                                                        <div class="iw bx l vd ve fr n ix fs"></div>
                                                    </div>
                                                </div>
                                            </a>
                                            <a href="https://towardsdatascience.com/?source=post_page-----a34a51b93873--------------------------------" rel="noopener follow">
                                                <div class="vf ab fi">
                                                    <div>
                                                        <div class="bl" aria-hidden="false">
                                                            <div class="l vg vh bx vc jb">
                                                                <div class="l fi">
                                                                    <img alt="Towards Data Science" class="l fc bx by bz cw" src="https://miro.medium.com/v2/resize:fill:64:64/1*CJe3891yB1A1mzMdqemkdg.jpeg" width="32" height="32" loading="lazy"/>
                                                                    <div class="iw bx l by bz fr n ix fs"></div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                        <div class="j i d">
                                            <div class="ab">
                                                <span>
                                                    <a class="be b bf z eo ty ep eq er es et eu ev ew ex ey ez vi fa fb fc bl fd fe" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc24a3d106811&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-math-behind-neural-networks-a34a51b93873&amp;user=Cristian+Leo&amp;userId=c24a3d106811&amp;source=post_page-c24a3d106811----a34a51b93873---------------------follow_profile-----------" rel="noopener follow">Follow</a>
                                                </span>
                                                <div class="ds l">
                                                    <div>
                                                        <div>
                                                            <div class="bl" aria-hidden="false">
                                                                <div class="l">
                                                                    <span>
                                                                        <a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5a6c71c2b112&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-math-behind-neural-networks-a34a51b93873&amp;newsletterV3=c24a3d106811&amp;newsletterV3Id=5a6c71c2b112&amp;user=Cristian+Leo&amp;userId=c24a3d106811&amp;source=-----a34a51b93873---------------------subscribe_user-----------" rel="noopener follow">
                                                                            <button class="be b bf z vk am vl vm vn vo vp vq vr vs ev ew ex ey ez fa fb fc bl fd fe" aria-label="Subscribe">
                                                                                <svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="vj vh vg">
                                                                                    <rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect>
                                                                                    <rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect>
                                                                                    <path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path>
                                                                                    <path d="M11.5 14.5L19 20l4-3"></path>
                                                                                </svg>
                                                                            </button>
                                                                        </a>
                                                                    </span>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                    <div class="ab cm co">
                                        <div class="l">
                                            <div class="ab q">
                                                <a class="af ag ah ai aj ak al am an ao ap aq ar as at ab q" href="https://medium.com/@cristianleo120?source=post_page-----a34a51b93873--------------------------------" rel="noopener follow">
                                                    <h2 class="pw-author-name be vt vu vv vw bj">
                                                        <span class="gn">Written by 
                                                        <!-- -->
                                                        Cristian Leo</span>
                                                    </h2>
                                                </a>
                                            </div>
                                            <div class="sx ab">
                                                <div class="l jo">
                                                    <span class="pw-follower-count be b bf z bj">
                                                        <a class="af ag ah ai aj ak al am an ao ap aq ar jh" href="https://medium.com/@cristianleo120/followers?source=post_page-----a34a51b93873--------------------------------" rel="noopener follow">11.4K Followers</a>
                                                    </span>
                                                </div>
                                                <div class="be b bf z jw jx jy ab ka kb kc kd dt ju">
                                                    <span class="ji l" aria-hidden="true">
                                                        <span class="be b bf z dt"></span>
                                                    </span>
                                                    <span class="l jo">Writer for </span>
                                                    <div>
                                                        <div class="l" aria-hidden="false">
                                                            <a class="af ag ah ai aj ak al am an ao ap aq ar jh ab q" href="https://towardsdatascience.com/?source=post_page-----a34a51b93873--------------------------------" rel="noopener follow">
                                                                <p class="be b bf z jw jx jy jz ka kb kc kd bj">Towards Data Science</p>
                                                            </a>
                                                        </div>
                                                    </div>
                                                </div>
                                            </div>
                                            <div class="vx l">
                                                <p class="be b bf z bj">
                                                    <span class="gn">A Data Scientist with a passion about recreating all the popular machine learning algorithm from scratch.</span>
                                                </p>
                                            </div>
                                        </div>
                                        <div class="h k">
                                            <div class="ab">
                                                <span>
                                                    <a class="be b bf z eo ty ep eq er es et eu ev ew ex ey ez vi fa fb fc bl fd fe" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc24a3d106811&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-math-behind-neural-networks-a34a51b93873&amp;user=Cristian+Leo&amp;userId=c24a3d106811&amp;source=post_page-c24a3d106811----a34a51b93873---------------------follow_profile-----------" rel="noopener follow">Follow</a>
                                                </span>
                                                <div class="ds l">
                                                    <div>
                                                        <div>
                                                            <div class="bl" aria-hidden="false">
                                                                <div class="l">
                                                                    <span>
                                                                        <a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5a6c71c2b112&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-math-behind-neural-networks-a34a51b93873&amp;newsletterV3=c24a3d106811&amp;newsletterV3Id=5a6c71c2b112&amp;user=Cristian+Leo&amp;userId=c24a3d106811&amp;source=-----a34a51b93873---------------------subscribe_user-----------" rel="noopener follow">
                                                                            <button class="be b bf z vk am vl vm vn vo vp vq vr vs ev ew ex ey ez fa fb fc bl fd fe" aria-label="Subscribe">
                                                                                <svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="vj vh vg">
                                                                                    <rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect>
                                                                                    <rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect>
                                                                                    <path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path>
                                                                                    <path d="M11.5 14.5L19 20l4-3"></path>
                                                                                </svg>
                                                                            </button>
                                                                        </a>
                                                                    </span>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                    <div class="vy bg vz wa wb wc wd we"></div>
                                </div>
                            </div>
                            <div class="h k j">
                                <div class="vy bg vz wf"></div>
                                <div class="ab ca">
                                    <div class="ch bg fz ga gb gc">
                                        <div class="wg ab lm jr">
                                            <div class="wh wi l">
                                                <a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://help.medium.com/hc/en-us?source=post_page-----a34a51b93873--------------------------------" rel="noopener follow">
                                                    <p class="be b du z dt">Help</p>
                                                </a>
                                            </div>
                                            <div class="wh wi l">
                                                <a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.statuspage.io/?source=post_page-----a34a51b93873--------------------------------" rel="noopener follow">
                                                    <p class="be b du z dt">Status</p>
                                                </a>
                                            </div>
                                            <div class="wh wi l">
                                                <a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/about?autoplay=1&amp;source=post_page-----a34a51b93873--------------------------------" rel="noopener follow">
                                                    <p class="be b du z dt">About</p>
                                                </a>
                                            </div>
                                            <div class="wh wi l">
                                                <a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----a34a51b93873--------------------------------" rel="noopener follow">
                                                    <p class="be b du z dt">Careers</p>
                                                </a>
                                            </div>
                                            <div class="wh wi l">
                                                <a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://blog.medium.com/?source=post_page-----a34a51b93873--------------------------------" rel="noopener follow">
                                                    <p class="be b du z dt">Blog</p>
                                                </a>
                                            </div>
                                            <div class="wh wi l">
                                                <a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a34a51b93873--------------------------------" rel="noopener follow">
                                                    <p class="be b du z dt">Privacy</p>
                                                </a>
                                            </div>
                                            <div class="wh wi l">
                                                <a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a34a51b93873--------------------------------" rel="noopener follow">
                                                    <p class="be b du z dt">Terms</p>
                                                </a>
                                            </div>
                                            <div class="wh wi l">
                                                <a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://speechify.com/medium?source=post_page-----a34a51b93873--------------------------------" rel="noopener follow">
                                                    <p class="be b du z dt">Text to speech</p>
                                                </a>
                                            </div>
                                            <div class="wh l">
                                                <a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/business?source=post_page-----a34a51b93873--------------------------------" rel="noopener follow">
                                                    <p class="be b du z dt">Teams</p>
                                                </a>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </body>
</html>